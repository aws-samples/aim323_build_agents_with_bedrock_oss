{
 "cells": [
  {
   "attachments": {
    "agents_memory_light.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Building a Travel Planner with a Simple LangGraph\n",
    "\n",
    "## Overview\n",
    "\n",
    "This lab guides you through the process of creating a simple Travel Planner using LangGraph, a library for building stateful, multi-step applications with language models. The Travel Planner demonstrates how to structure a conversational AI application that collects user input and generates personalized travel itineraries.\n",
    "\n",
    "#### What gets covered in this lab: \n",
    "we wil cover these aspects below:\n",
    "- LangGraph constructs for how to build Agentic systems with Graph\n",
    "- Introduction to short term and long term memory for 'turn-by-turn' conversations\n",
    "\n",
    "## Intro to Agents\n",
    "\n",
    "Agents are intelligent systems or components that utilize Large Language Models (LLMs) to perform tasks in a dynamic and autonomous manner. Here's a breakdown of the key concepts:\n",
    "\n",
    "### What Are Agents?\n",
    "1. Step-by-Step Thinking: Agents leverage LLMs to think and reason through problems in a structured way, often referred to as chain-of-thought reasoning. This allows them to plan, evaluate, and execute tasks effectively.\n",
    "2. Access to Tools: Agents can utilize external tools (e.g., calculators, databases, APIs) to enhance their decision-making and problem-solving capabilities.\n",
    "3. Access to Memory: Agents can store and retrieve context, enabling them to work on tasks over time, adapt to user interactions, and handle complex workflows.\n",
    "\n",
    "**Key characteristics of AI agents include:**\n",
    "\n",
    "**Perception:** The ability to gather information from their environment through sensors or data inputs.\n",
    "**Decision-making:** Using AI algorithms to process information and determine the best course of action.\n",
    "**Action:** The capability to execute decisions and interact with the environment or users.\n",
    "**Learning:** The ability to improve performance over time through experience and feedback.\n",
    "**Autonomy:** Operating independently to some degree, without constant human intervention.\n",
    "**Goal-oriented:** Working towards specific objectives or tasks.\n",
    "\n",
    "![agents_memory_light.png](attachment:agents_memory_light.png)\n",
    "\n",
    "## Use Case Details\n",
    "\n",
    "Our Travel Planner follows a straightforward, three-step process:\n",
    "\n",
    "1. **Initial User Input**: \n",
    "   - The application prompts the user to enter their desired travel plan to get assistance from AI Agent.\n",
    "   - This information is stored in the state.\n",
    "\n",
    "2. **Interests Input**:\n",
    "   - The user is asked to provide their interests for the trip.\n",
    "   - These interests are stored as a list in the state.\n",
    "\n",
    "3. **Itinerary Creation**:\n",
    "   - Using the collected city and interests, the application leverages a language model to generate a personalized day trip itinerary.\n",
    "   - The generated itinerary is presented to the user.\n",
    "\n",
    "The flow between these steps is managed by LangGraph, which handles the state transitions and ensures that each step is executed in the correct order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Imports\n",
    "\n",
    "First, let's import the necessary modules and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U --no-cache-dir  \\\n",
    "# \"langchain==0.3.7\" \\\n",
    "# \"langchain-aws==0.2.6\" \\\n",
    "# \"langchain-community==0.3.5\" \\\n",
    "# \"langchain-text-splitters==0.3.2\" \\\n",
    "# \"langchainhub==0.1.20\" \\\n",
    "# \"langgraph==0.2.45\" \\\n",
    "# \"langgraph-checkpoint==2.0.2\" \\\n",
    "# \"langgraph-sdk==0.1.35\" \\\n",
    "# \"langsmith==0.1.140\" \\\n",
    "# \"pypdf==3.8,<4\" \\\n",
    "# \"ipywidgets>=7,<8\" \\\n",
    "# \"matplotlib==3.9.0\" \\\n",
    "# \"faiss-cpu==1.8.0\"\n",
    "\n",
    "# %pip install -U --no-cache-dir transformers\n",
    "# %pip install -U --no-cache-dir boto3\n",
    "# %pip install grandalf==3.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import display, Image\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "#load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph Basics\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **StateGraph**\n",
    "   - This object will encapsulate the graph being traversed during excecution.\n",
    "   - The core of our application, defining the flow of our Travel Planner.\n",
    "   - PlannerState, a custom type representing the state of our planning process.\n",
    "\n",
    "2. **Nodes**\n",
    "    - In LangGraph, nodes are typically python functions.\n",
    "    - There are two main nodes we will use for our graph:\n",
    "        - The agent node: responsible for deciding what (if any) actions to take.\n",
    "        - The tool node: This node will orchestrate calling the respective tool and returning the output. \n",
    "4. **Edges**\n",
    "   - Defines how the logic is routed and how the graph decides to stop.\n",
    "   - Defines how your agents work and how different nodes communicate with each other.\n",
    "   - There are a few key types of edges:\n",
    "        - Normal Edges: Go directly from one node to the next.\n",
    "        - Conditional Edges: Call a function to determine which node(s) to go to next.\n",
    "        - Entry Point: Which node to call first when user input arrives.\n",
    "        - Conditional Entry Point: Call a function to determine which node(s) to call first when user input arrives.\n",
    "\n",
    "4. **LLM Integration**: Utilizing a language model to generate the final itinerary.\n",
    "5. **Memory Integration**: Utilizing long term and short term memory for conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Agent State\n",
    "\n",
    "We'll define the state that our agent will maintain throughout its operation. First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph.  The State schema serves as the input schema for all Nodes and Edges in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlannerState(TypedDict):\n",
    "    messages: Annotated[List[HumanMessage | AIMessage], \"The messages in the conversation\"]\n",
    "    itinerary: str\n",
    "    city: str\n",
    "    user_message: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Language Model and Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsgrewal/conda/virtualenv/trainenv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_arn\" in BedrockRerank has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import ChatBedrock\n",
    "import boto3\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "provider_id = \"anthropic\"\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=model_id,\n",
    "    provider=provider_id,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    ")\n",
    "\n",
    "itinerary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful travel assistant. Create a day trip itinerary for {city} based on the user's interests. \n",
    "    Follow these instructions:\n",
    "    1. Use the below chat conversation and the latest input from Human to get the user interests.\n",
    "    2. Always account for travel time and meal times - if its not possible to do everything, then say so.\n",
    "    3. If the user hasn't stated a time of year or season, assume summer season in {city} and state this assumption in your response.\n",
    "    4. If the user hasn't stated a travel budget, assume a reasonable dollar amount and state this assumption in your response.\n",
    "    5. Provide a brief, bulleted itinerary in chronological order with specific hours of day.\"\"\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{user_message}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the nodes and Edges\n",
    "\n",
    "We are adding the nodes, edges as well as a persistant memory to the ```StateGraph``` before we compile it. \n",
    "- user travel plans\n",
    "- invoke with Bedrock\n",
    "- generate the travel plan for the day \n",
    "- ability to add or modify the plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def input_interests(state: PlannerState) -> PlannerState:\n",
    "    user_message = state['user_message'] #input(\"Your input: \")\n",
    "    #print(f\"We are going to :: {user_message}:: for trip to {state['city']} based on your interests mentioned in the prompt....\")\n",
    "\n",
    "    if not state.get('messages', None) : state['messages'] = []\n",
    "    return {\n",
    "        **state,\n",
    "    }\n",
    "\n",
    "def create_itinerary(state: PlannerState) -> PlannerState:\n",
    "    response = llm.invoke(itinerary_prompt.format_messages(city=state['city'], user_message=state['user_message'], chat_history=state['messages']))\n",
    "    print(\"\\nFinal Itinerary:\")\n",
    "    print(response.content)\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": state['messages'] + [HumanMessage(content=state['user_message']), AIMessage(content=response.content)],\n",
    "        \"itinerary\": response.content\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Compile the Graph\n",
    "\n",
    "Now we'll create our LangGraph workflow and compile it. \n",
    " \n",
    "- First, we initialize a StateGraph with the `State` class we defined above.\n",
    "- Then, we add our nodes and edges.\n",
    "- We use the [`START` Node, a special node](https://langchain-ai.github.io/langgraph/concepts/low_level/#start-node) that sends user input to the graph, to indicate where to start our graph.\n",
    "- The [`END` Node](https://langchain-ai.github.io/langgraph/concepts/low_level/#end-node) is a special node that represents a terminal node. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(PlannerState)\n",
    "\n",
    "#workflow.add_node(\"input_city\", input_city)\n",
    "workflow.add_node(\"input_interests\", input_interests)\n",
    "workflow.add_node(\"create_itinerary\", create_itinerary)\n",
    "\n",
    "workflow.set_entry_point(\"input_interests\")\n",
    "\n",
    "#workflow.add_edge(\"input_city\", \"input_interests\")\n",
    "workflow.add_edge(\"input_interests\", \"create_itinerary\")\n",
    "workflow.add_edge(\"create_itinerary\", END)\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# this is a complete memory for the entire graph.\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the graph structure\n",
    "\n",
    "Finally, we [compile our graph](https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) to perform a few basic checks on the graph structure. We can visualize the graph as a [Mermaid diagram](https://github.com/mermaid-js/mermaid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function that runs the graph\n",
    "\n",
    "When we compile the graph, we turn it into a LangChain Runnable, which automatically enables calling `.invoke()`, `.stream()` and `.batch()` with your inputs. In the following example, we run `stream()` to invoke the graph with inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_travel_planner(user_request: str, config_dict: dict):\n",
    "    print(f\"Current User Request: {user_request}\\n\")\n",
    "    init_input = {\"user_message\": user_request,\"city\" : \"Seattle\"}\n",
    "\n",
    "    for output in app.stream(init_input, config=config_dict, stream_mode=\"values\"):\n",
    "        pass  # The nodes themselves now handle all printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travel Planner Example\n",
    "\n",
    "- To run this the system prompts and asks for user input for activities \n",
    "- We have initialized the graph state with city Seattle which usually will be dynamic and we will see in subsequrnt labs\n",
    "- You can enter like boating, swiming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current User Request: Can you create a itinerary for a day trip in Seattle with boating and swimming options. Need a complete plan\n",
      "\n",
      "\n",
      "Final Itinerary:\n",
      "Okay, got it. Let's plan a day trip in Seattle for you with boating and swimming options.\n",
      "\n",
      "Assuming you're visiting in the summer season and have a reasonable travel budget, here's a suggested itinerary:\n",
      "\n",
      "Morning (9 AM - 12 PM):\n",
      "- Start your day with a scenic ferry ride to Bainbridge Island. The 35-minute ferry crossing offers beautiful views of the Seattle skyline and Puget Sound. \n",
      "- Once on the island, explore the charming downtown area and grab a coffee or breakfast at one of the local cafes.\n",
      "\n",
      "Afternoon (12 PM - 4 PM):\n",
      "- Head back to Seattle and visit Alki Beach, a popular spot for swimming, sunbathing, and taking in the views of the city skyline across the Puget Sound.\n",
      "- Rent a kayak or stand-up paddleboard and spend an hour or two exploring the calm waters around Alki Beach.\n",
      "- Have a leisurely lunch at one of the beachfront restaurants, enjoying fresh seafood and local Pacific Northwest cuisine.\n",
      "\n",
      "Late Afternoon (4 PM - 6 PM):\n",
      "- Visit the Chittenden Locks in Ballard, also known as the Ballard Locks. This engineering marvel connects the saltwater of Puget Sound to the freshwater of Lake Union and Lake Washington. Observe the boats passing through the locks and explore the surrounding gardens.\n",
      "\n",
      "Evening (6 PM - 8 PM):\n",
      "- Finish your day with a scenic cruise on Lake Union. Many tour companies offer evening cruises that provide stunning views of the Seattle skyline, the floating homes, and the bustling activity on the lake.\n",
      "\n",
      "This itinerary should give you a well-rounded day in Seattle, allowing you to experience the city's natural beauty, outdoor activities, and iconic landmarks. Let me know if you need any clarification or have additional requests!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_request = \"Can you create a itinerary for a day trip in Seattle with boating and swimming options. Need a complete plan\"\n",
    "run_travel_planner(user_request, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leverage the memory saver to manipulate the Graph State\n",
    "- Since the `Conversation Messages` are part of the graph state we can leverage that\n",
    "- However the graph state is tied to `session_id` which will be passed in as a `thread_id` which ties to a session\n",
    "- If we add a request with different thread id it will create a new session which will not have the previous `Interests`\n",
    "- However this this has the other check points variables as well and so this pattern is good for `A-Sync` workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current User Request: Can you add white water rafting to this itinerary\n",
      "\n",
      "\n",
      "Final Itinerary:\n",
      "Okay, let's add white water rafting to the Seattle day trip itinerary:\n",
      "\n",
      "Morning (9 AM - 12 PM):\n",
      "- Start your day with a scenic ferry ride to Bainbridge Island. The 35-minute ferry crossing offers beautiful views of the Seattle skyline and Puget Sound.\n",
      "- Once on the island, explore the charming downtown area and grab a coffee or breakfast at one of the local cafes.\n",
      "\n",
      "Afternoon (12 PM - 4 PM):\n",
      "- Head back to Seattle and drive about 45 minutes to the Snoqualmie River, where you'll enjoy a white water rafting adventure. This will be an exciting addition to your day, with Class II-III rapids to navigate.\n",
      "- After your rafting trip, have a leisurely lunch at one of the riverside restaurants.\n",
      "\n",
      "Late Afternoon (4 PM - 6 PM): \n",
      "- Visit the Chittenden Locks in Ballard, also known as the Ballard Locks. This engineering marvel connects the saltwater of Puget Sound to the freshwater of Lake Union and Lake Washington. Observe the boats passing through the locks and explore the surrounding gardens.\n",
      "\n",
      "Evening (6 PM - 8 PM):\n",
      "- Finish your day with a scenic cruise on Lake Union. Many tour companies offer evening cruises that provide stunning views of the Seattle skyline, the floating homes, and the bustling activity on the lake.\n",
      "\n",
      "Please note that adding the white water rafting activity means you'll have a more packed afternoon, with less time for exploring Alki Beach. However, this revised itinerary should still provide a great mix of outdoor activities, sightseeing, and relaxation during your day in Seattle.\n",
      "\n",
      "Let me know if you have any other questions or need further adjustments to the itinerary.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_request = \"Can you add white water rafting to this itinerary\"\n",
    "run_travel_planner(user_request, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run with another session\n",
    "\n",
    "Now this session will not have the previous conversations and we see it will create a new travel plan with the `white water rafting`  interests, not boating or swim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current User Request: Can you add white water rafting to itinerary\n",
      "\n",
      "\n",
      "Final Itinerary:\n",
      "Okay, got it. Based on our previous conversation, it seems your interests include:\n",
      "\n",
      "- Visiting the Space Needle\n",
      "- Exploring Pike Place Market\n",
      "- Going on a white water rafting adventure\n",
      "\n",
      "Assuming you're visiting Seattle in the summer season and have a reasonable travel budget, here's a suggested day trip itinerary:\n",
      "\n",
      "9:00 AM - Start your day at the iconic Space Needle. Spend 1-2 hours taking in the 360-degree views of the city from the observation deck.\n",
      "\n",
      "11:00 AM - Head to the lively Pike Place Market. Wander through the stalls, sample local produce and seafood, and watch the famous fish throwing demonstrations. Plan to spend 1-2 hours exploring the market.\n",
      "\n",
      "1:00 PM - Break for lunch at one of the many restaurants or food vendors in the Pike Place area. \n",
      "\n",
      "2:30 PM - Depart for your white water rafting adventure, which will likely be located outside the city center, about a 30-45 minute drive away. Plan to spend 2-3 hours on the river, including transportation time.\n",
      "\n",
      "5:30 PM - Return to the city center. You may have time for a quick visit to the Chihuly Garden and Glass exhibit or the Museum of Pop Culture (MoPOP) before heading back.\n",
      "\n",
      "7:00 PM - End your day with a scenic dinner overlooking the Puget Sound or the city skyline.\n",
      "\n",
      "Please note that fitting in all these activities in a single day may be ambitious, and you may need to prioritize or adjust the schedule based on your energy levels and interests on the day. Let me know if you have any other questions!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"11\"}}\n",
    "\n",
    "user_request = \"Can you add white water rafting to itinerary\"\n",
    "run_travel_planner(user_request, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "Memory is key for any agentic conversation which is `Multi-Turn` or `Multi-Agent` colloboration conversation and more so if it spans multiple days. The 3 main aspects of Agents are:\n",
    "1. Tools\n",
    "2. Memory\n",
    "3. Planners\n",
    "\n",
    "\n",
    "### Explore `External Store` for memory\n",
    "\n",
    "\n",
    "There are 2 types of memory for AI Agents, short term and long term memory which can be explained below. \n",
    "Further reading can be at this [link](https://langchain-ai.github.io/langgraph/concepts/memory/#what-is-memory)\n",
    "\n",
    "Conversation memory can be explained by this diagram below which explains the `turn by turn` conversations which needs to be accessed by agents and then saved as a summary for long term memory\n",
    "\n",
    "<img src=\"./images/short-vs-long.png\" width=\"45%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an external `Memory persistence`\n",
    "\n",
    "In this section we will leverage multi-thread, multi-session persistence to Chat Messages. Ideally you will leverage persistence like Redis Store etc to save messages per session\n",
    "\n",
    "##### Memory Management\n",
    "- We can have several Patterns - we can have each Agents with it's own Session memory\n",
    "- Or we can have the whole Graph have a combined memory in which case each agent will get it's own memory\n",
    "\n",
    "The MemorySaver or the Store have the concept of separating sections of memory by Namespaces or by Thread ID's and those can be leveraged to either 1/ Use the graph level message or memory 2/ Ecah agent can have it's own memory via space in saver or else having it's own saver like we do in the `ReACT agent`\n",
    "\n",
    "<img src=\"./images/multi_memory_light.png\" width=\"60%\" alt='multi_memory_light.png' /> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.base import BaseStore, Item, Op, Result\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from typing import Any, Iterable, Literal, NamedTuple, Optional, Union, cast\n",
    "\n",
    "class CustomMemoryStore(BaseStore):\n",
    "\n",
    "    def __init__(self, ext_store):\n",
    "        self.store = ext_store\n",
    "\n",
    "    def get(self, namespace: tuple[str, ...], key: str) -> Optional[Item]:\n",
    "        return self.store.get(namespace,key)\n",
    "\n",
    "    def put(self, namespace: tuple[str, ...], key: str, value: dict[str, Any]) -> None:\n",
    "        return self.store.put(namespace, key, value)\n",
    "    async def aget(self, namespace: tuple[str, ...], key: str) -> Optional[Item]:\n",
    "        res = await self.get(namespace,key)\n",
    "        return res\n",
    "    async def aput(self, namespace: tuple[str, ...], key: str, value: dict[str, Any]) -> None:\n",
    "        res = await self.put(namespace, key, value)\n",
    "        return res\n",
    "    def batch(self, ops: Iterable[Op]) -> list[Result]:\n",
    "        return self.store.batch(ops)\n",
    "    async def abatch(self, ops: Iterable[Op]) -> list[Result]:\n",
    "        res = await self.store.abatch(ops)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick look at how to use this store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': ['list a']} ['list a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('chat_messages', 'user_id_1')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_memory_store = CustomMemoryStore(InMemoryStore())\n",
    "namespace_u = (\"chat_messages\", \"user_id_1\")\n",
    "key_u=\"user_id_1\"\n",
    "in_memory_store.put(namespace_u, key_u, {\"data\":[\"list a\"]})\n",
    "item_u = in_memory_store.get(namespace_u, key_u)\n",
    "print(item_u.value, item_u.value['data'])\n",
    "\n",
    "in_memory_store.list_namespaces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the similiar graph as earlier -- note we will not have any mesages in the Graph state as that has been externalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlannerState(TypedDict):\n",
    "    itinerary: str\n",
    "    city: str\n",
    "    user_message: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_interests(state: PlannerState, config: RunnableConfig, *, store: BaseStore) -> PlannerState:\n",
    "    user_message = state['user_message'] #input(\"Your input: \")\n",
    "    return {\n",
    "        **state,\n",
    "    }\n",
    "\n",
    "def create_itinerary(state: PlannerState, config: RunnableConfig, *, store: BaseStore) -> PlannerState:\n",
    "    #- get the history from the store\n",
    "    user_u = f\"user_id_{config['configurable']['thread_id']}\"\n",
    "    namespace_u = (\"chat_messages\", user_u)\n",
    "    store_item = store.get(namespace=namespace_u, key=user_u)\n",
    "    chat_history_messages = store_item.value['data'] if store_item else []\n",
    "    print(user_u,chat_history_messages)\n",
    "\n",
    "    response = llm.invoke(itinerary_prompt.format_messages(city=state['city'], user_message=state['user_message'], chat_history=chat_history_messages))\n",
    "    print(\"\\nFinal Itinerary:\")\n",
    "    print(response.content)\n",
    "\n",
    "    #- add back to the store\n",
    "    store.put(namespace=namespace_u, key=user_u, value={\"data\":chat_history_messages+[HumanMessage(content=state['user_message']),AIMessage(content=response.content)]})\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"itinerary\": response.content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_memory_store_n = CustomMemoryStore(InMemoryStore())\n",
    "\n",
    "workflow = StateGraph(PlannerState)\n",
    "\n",
    "#workflow.add_node(\"input_city\", input_city)\n",
    "workflow.add_node(\"input_interests\", input_interests)\n",
    "workflow.add_node(\"create_itinerary\", create_itinerary)\n",
    "\n",
    "workflow.set_entry_point(\"input_interests\")\n",
    "\n",
    "#workflow.add_edge(\"input_city\", \"input_interests\")\n",
    "workflow.add_edge(\"input_interests\", \"create_itinerary\")\n",
    "workflow.add_edge(\"create_itinerary\", END)\n",
    "\n",
    "\n",
    "app = workflow.compile(store=in_memory_store_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current User Request: Can you create a itinerary for a day trip in california with boating and swimming options.  I need a complete plan that budgets for travel time and meal time.\n",
      "\n",
      "user_id_1 []\n",
      "\n",
      "Final Itinerary:\n",
      "Okay, got it. Let's plan a day trip itinerary for you in Seattle, since you didn't specify a location in California. \n",
      "\n",
      "Based on your interest in boating and swimming, here's a suggested one-day itinerary for Seattle in the summer season:\n",
      "\n",
      "Assumptions:\n",
      "- Travel budget: Approximately $100-150 per person\n",
      "- Season: Summer\n",
      "\n",
      "Itinerary:\n",
      "\n",
      "9:00 AM - Start your day at Alki Beach. Enjoy the scenic views of the Puget Sound and the Olympic Mountains. Take a stroll along the boardwalk and dip your toes in the water.\n",
      "\n",
      "11:00 AM - Head to Fishermen's Terminal and take a 1-hour sightseeing cruise around the harbor. You'll get to see the Seattle skyline, the Ballard Locks, and possibly some marine wildlife.\n",
      "\n",
      "12:30 PM - Grab lunch at one of the seafood restaurants in the Ballard neighborhood, such as Salmon Bay Sand & Gravel or Ray's Boathouse.\n",
      "\n",
      "2:00 PM - Drive to Seward Park and explore the 300-acre peninsula. Hike one of the trails, visit the environmental learning center, or rent a kayak or paddleboard to enjoy the lake.\n",
      "\n",
      "4:30 PM - Visit the Chihuly Garden and Glass, a stunning exhibition showcasing the vibrant and whimsical glass art of Dale Chihuly.\n",
      "\n",
      "6:30 PM - End your day with a scenic ferry ride from downtown Seattle to Bainbridge Island. Enjoy the views of the city skyline and the Puget Sound as you cross.\n",
      "\n",
      "Please note that this itinerary includes travel time between locations and allows for meal breaks. However, it may not be possible to fit everything in, depending on your pace and interests. Let me know if you would like me to modify or adjust the itinerary further.\n"
     ]
    }
   ],
   "source": [
    "def run_travel_planner(user_request: str, config_dict: dict):\n",
    "    print(f\"Current User Request: {user_request}\\n\")\n",
    "    init_input = {\"user_message\": user_request,\"city\" : \"Seattle\"}\n",
    "\n",
    "    for output in app.stream(init_input, config=config_dict, stream_mode=\"values\"):\n",
    "        pass  # The nodes themselves now handle all printing\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_request = \"Can you create a itinerary for a day trip in california with boating and swimming options.  I need a complete plan that budgets for travel time and meal time.\"\n",
    "run_travel_planner(user_request, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current User Request: Can you add itinerary for white water rafting to this\n",
      "\n",
      "user_id_1 [HumanMessage(content='Can you create a itinerary for a day trip in california with boating and swimming options.  I need a complete plan that budgets for travel time and meal time.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Okay, got it. Let's plan a day trip itinerary for you in Seattle, since you didn't specify a location in California. \\n\\nBased on your interest in boating and swimming, here's a suggested one-day itinerary for Seattle in the summer season:\\n\\nAssumptions:\\n- Travel budget: Approximately $100-150 per person\\n- Season: Summer\\n\\nItinerary:\\n\\n9:00 AM - Start your day at Alki Beach. Enjoy the scenic views of the Puget Sound and the Olympic Mountains. Take a stroll along the boardwalk and dip your toes in the water.\\n\\n11:00 AM - Head to Fishermen's Terminal and take a 1-hour sightseeing cruise around the harbor. You'll get to see the Seattle skyline, the Ballard Locks, and possibly some marine wildlife.\\n\\n12:30 PM - Grab lunch at one of the seafood restaurants in the Ballard neighborhood, such as Salmon Bay Sand & Gravel or Ray's Boathouse.\\n\\n2:00 PM - Drive to Seward Park and explore the 300-acre peninsula. Hike one of the trails, visit the environmental learning center, or rent a kayak or paddleboard to enjoy the lake.\\n\\n4:30 PM - Visit the Chihuly Garden and Glass, a stunning exhibition showcasing the vibrant and whimsical glass art of Dale Chihuly.\\n\\n6:30 PM - End your day with a scenic ferry ride from downtown Seattle to Bainbridge Island. Enjoy the views of the city skyline and the Puget Sound as you cross.\\n\\nPlease note that this itinerary includes travel time between locations and allows for meal breaks. However, it may not be possible to fit everything in, depending on your pace and interests. Let me know if you would like me to modify or adjust the itinerary further.\", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "Final Itinerary:\n",
      "Okay, great! Let's add a white water rafting activity to the Seattle day trip itinerary. Here's the updated plan:\n",
      "\n",
      "Assumptions:\n",
      "- Travel budget: Approximately $150-200 per person\n",
      "- Season: Summer\n",
      "\n",
      "Itinerary:\n",
      "\n",
      "9:00 AM - Start your day at Alki Beach. Enjoy the scenic views of the Puget Sound and the Olympic Mountains. Take a stroll along the boardwalk and dip your toes in the water.\n",
      "\n",
      "11:00 AM - Head to Fishermen's Terminal and take a 1-hour sightseeing cruise around the harbor. You'll get to see the Seattle skyline, the Ballard Locks, and possibly some marine wildlife.\n",
      "\n",
      "12:30 PM - Grab lunch at one of the seafood restaurants in the Ballard neighborhood, such as Salmon Bay Sand & Gravel or Ray's Boathouse.\n",
      "\n",
      "2:00 PM - Drive to Snoqualmie River, about a 45-minute drive from Seattle, and join a white water rafting tour. Spend 2-3 hours navigating the Class III-IV rapids with a experienced guide.\n",
      "\n",
      "5:30 PM - After the rafting adventure, head to Seward Park and explore the 300-acre peninsula. Hike one of the trails, visit the environmental learning center, or rent a kayak or paddleboard to enjoy the lake.\n",
      "\n",
      "7:30 PM - Visit the Chihuly Garden and Glass, a stunning exhibition showcasing the vibrant and whimsical glass art of Dale Chihuly.\n",
      "\n",
      "9:00 PM - End your day with a scenic ferry ride from downtown Seattle to Bainbridge Island. Enjoy the views of the city skyline and the Puget Sound as you cross.\n",
      "\n",
      "Please note that the white water rafting activity will take up a significant portion of the afternoon, so we've adjusted the schedule accordingly. Let me know if you have any other questions or need further modifications to the itinerary.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_request = \"Can you add itinerary for white water rafting to this\"\n",
    "run_travel_planner(user_request, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick look at the store\n",
    "\n",
    "it will show the History of the Chat Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chat_messages', 'user_id_1')]\n",
      "{'data': [HumanMessage(content='Can you create a itinerary for a day trip in california with boating and swimming options.  I need a complete plan that budgets for travel time and meal time.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Okay, got it. Let's plan a day trip itinerary for you in Seattle, since you didn't specify a location in California. \\n\\nBased on your interest in boating and swimming, here's a suggested one-day itinerary for Seattle in the summer season:\\n\\nAssumptions:\\n- Travel budget: Approximately $100-150 per person\\n- Season: Summer\\n\\nItinerary:\\n\\n9:00 AM - Start your day at Alki Beach. Enjoy the scenic views of the Puget Sound and the Olympic Mountains. Take a stroll along the boardwalk and dip your toes in the water.\\n\\n11:00 AM - Head to Fishermen's Terminal and take a 1-hour sightseeing cruise around the harbor. You'll get to see the Seattle skyline, the Ballard Locks, and possibly some marine wildlife.\\n\\n12:30 PM - Grab lunch at one of the seafood restaurants in the Ballard neighborhood, such as Salmon Bay Sand & Gravel or Ray's Boathouse.\\n\\n2:00 PM - Drive to Seward Park and explore the 300-acre peninsula. Hike one of the trails, visit the environmental learning center, or rent a kayak or paddleboard to enjoy the lake.\\n\\n4:30 PM - Visit the Chihuly Garden and Glass, a stunning exhibition showcasing the vibrant and whimsical glass art of Dale Chihuly.\\n\\n6:30 PM - End your day with a scenic ferry ride from downtown Seattle to Bainbridge Island. Enjoy the views of the city skyline and the Puget Sound as you cross.\\n\\nPlease note that this itinerary includes travel time between locations and allows for meal breaks. However, it may not be possible to fit everything in, depending on your pace and interests. Let me know if you would like me to modify or adjust the itinerary further.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you add itinerary for white water rafting to this', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Okay, great! Let's add a white water rafting activity to the Seattle day trip itinerary. Here's the updated plan:\\n\\nAssumptions:\\n- Travel budget: Approximately $150-200 per person\\n- Season: Summer\\n\\nItinerary:\\n\\n9:00 AM - Start your day at Alki Beach. Enjoy the scenic views of the Puget Sound and the Olympic Mountains. Take a stroll along the boardwalk and dip your toes in the water.\\n\\n11:00 AM - Head to Fishermen's Terminal and take a 1-hour sightseeing cruise around the harbor. You'll get to see the Seattle skyline, the Ballard Locks, and possibly some marine wildlife.\\n\\n12:30 PM - Grab lunch at one of the seafood restaurants in the Ballard neighborhood, such as Salmon Bay Sand & Gravel or Ray's Boathouse.\\n\\n2:00 PM - Drive to Snoqualmie River, about a 45-minute drive from Seattle, and join a white water rafting tour. Spend 2-3 hours navigating the Class III-IV rapids with a experienced guide.\\n\\n5:30 PM - After the rafting adventure, head to Seward Park and explore the 300-acre peninsula. Hike one of the trails, visit the environmental learning center, or rent a kayak or paddleboard to enjoy the lake.\\n\\n7:30 PM - Visit the Chihuly Garden and Glass, a stunning exhibition showcasing the vibrant and whimsical glass art of Dale Chihuly.\\n\\n9:00 PM - End your day with a scenic ferry ride from downtown Seattle to Bainbridge Island. Enjoy the views of the city skyline and the Puget Sound as you cross.\\n\\nPlease note that the white water rafting activity will take up a significant portion of the afternoon, so we've adjusted the schedule accordingly. Let me know if you have any other questions or need further modifications to the itinerary.\", additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "print(in_memory_store_n.list_namespaces())\n",
    "print(in_memory_store_n.get(('chat_messages', 'user_id_1'),'user_id_1').value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we review the concept of having Each `Agent` be backed by it's own memory\n",
    "\n",
    "For this we will leverage the RunnableWithMessageHistory when creating the agent\n",
    "- Here we create to simulate a InMemoryChatMessageHistory, but this will be externalized in produftion use cases\n",
    "- use this this as a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "#model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"#\n",
    "#model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "\n",
    "provider_id = \"anthropic\"\n",
    "\n",
    "chatbedrock_llm = ChatBedrockConverse(\n",
    "    model=model_id,\n",
    "    provider=provider_id,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "\n",
    "itinerary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful travel assistant. Create a day trip itinerary for {city} based on the user's interests. \n",
    "    Follow these instructions:\n",
    "    1. Use the below chat conversation and the latest input from Human to get the user interests.\n",
    "    2. Always account for travel time and meal times - if its not possible to do everything, then say so.\n",
    "    3. If the user hasn't stated a time of year or season, assume summer season in {city} and state this assumption in your response.\n",
    "    4. If the user hasn't stated a travel budget, assume a reasonable dollar amount and state this assumption in your response.\n",
    "    5. Provide a brief, bulleted itinerary in chronological order with specific hours of day.\"\"\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{user_message}\"),\n",
    "])\n",
    "chain = itinerary_prompt | chatbedrock_llm \n",
    "\n",
    "\n",
    "history = InMemoryChatMessageHistory()\n",
    "def get_history():\n",
    "    return history\n",
    "\n",
    "wrapped_chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_history,\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlannerState(TypedDict):\n",
    "    itinerary: str\n",
    "    city: str\n",
    "    user_message: str\n",
    "\n",
    "def input_interests(state: PlannerState, config: RunnableConfig, *, store: BaseStore) -> PlannerState:\n",
    "    user_message = state['user_message'] #input(\"Your input: \")\n",
    "    return {\n",
    "        **state,\n",
    "    }\n",
    "\n",
    "def create_itinerary(state: PlannerState, config: RunnableConfig, *, store: BaseStore) -> PlannerState:\n",
    "    #- each agent manages it's memory\n",
    "    response = wrapped_chain.invoke({\"city\": state['city'], \"user_message\": state['user_message'], \"input\": state['user_message']} )\n",
    "    print(\"\\nFinal Itinerary:\")\n",
    "    print(response.content)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"itinerary\": response.content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(PlannerState)\n",
    "\n",
    "#workflow.add_node(\"input_city\", input_city)\n",
    "workflow.add_node(\"input_interests\", input_interests)\n",
    "workflow.add_node(\"create_itinerary\", create_itinerary)\n",
    "\n",
    "workflow.set_entry_point(\"input_interests\")\n",
    "\n",
    "#workflow.add_edge(\"input_city\", \"input_interests\")\n",
    "workflow.add_edge(\"input_interests\", \"create_itinerary\")\n",
    "workflow.add_edge(\"create_itinerary\", END)\n",
    "\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current User Request: Can you create a itinerary for boating, swim. Need a complete plan\n",
      "\n",
      "\n",
      "Final Itinerary:\n",
      "Okay, got it. Based on your interest in boating and swimming, here is a suggested day trip itinerary for Seattle:\n",
      "\n",
      "Assumptions:\n",
      "- Visiting in the summer season\n",
      "- Reasonable travel budget of $100-200 per person\n",
      "\n",
      "Itinerary:\n",
      "\n",
      "9:00 AM - Start your day at Fishermen's Terminal, home to the largest commercial fishing fleet in the Pacific Northwest. Explore the docks and watch the boats come and go.\n",
      "\n",
      "10:30 AM - Head to Alki Beach, one of Seattle's most popular beaches. Spend a couple hours swimming, sunbathing, and enjoying the views of the Puget Sound and the Olympic Mountains.\n",
      "\n",
      "12:30 PM - Grab lunch at one of the beachfront restaurants or cafes on Alki, such as Salty's on Alki or Pegasus Pizza & Pasta.\n",
      "\n",
      "2:00 PM - Take a ferry ride across the Puget Sound to Bainbridge Island. Rent a kayak or stand-up paddleboard and explore the scenic coastline.\n",
      "\n",
      "4:30 PM - Return to Seattle via the ferry and head to Lake Union. Visit the Center for Wooden Boats and take a guided boat tour to learn about the city's maritime history.\n",
      "\n",
      "6:00 PM - End your day with dinner at one of the restaurants along the Lake Union waterfront, such as Duke's Seafood & Chowder or Ivar's Salmon House.\n",
      "\n",
      "Please note that this itinerary is quite full, and you may not be able to fit everything in depending on your pace and any unexpected delays. Let me know if you would like me to modify or adjust the plan in any way.\n"
     ]
    }
   ],
   "source": [
    "def run_travel_planner(user_request: str, config_dict: dict):\n",
    "    print(f\"Current User Request: {user_request}\\n\")\n",
    "    init_input = {\"user_message\": user_request,\"city\" : \"Seattle\"}\n",
    "\n",
    "    for output in app.stream(init_input, config=config_dict, stream_mode=\"values\"):\n",
    "        pass  # The nodes themselves now handle all printing\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_request = \"Can you create a itinerary for boating, swim. Need a complete plan\"\n",
    "run_travel_planner(user_request, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current User Request: Can you add white water rafting to this itinerary\n",
      "\n",
      "\n",
      "Final Itinerary:\n",
      "Okay, got it. Let's add white water rafting to the Seattle day trip itinerary:\n",
      "\n",
      "Assumptions:\n",
      "- Visiting in the summer season\n",
      "- Reasonable travel budget of $100-200 per person\n",
      "\n",
      "Itinerary:\n",
      "\n",
      "9:00 AM - Start your day at Fishermen's Terminal, home to the largest commercial fishing fleet in the Pacific Northwest. Explore the docks and watch the boats come and go.\n",
      "\n",
      "10:30 AM - Head to Alki Beach, one of Seattle's most popular beaches. Spend a couple hours swimming, sunbathing, and enjoying the views of the Puget Sound and the Olympic Mountains.\n",
      "\n",
      "12:30 PM - Grab lunch at one of the beachfront restaurants or cafes on Alki, such as Salty's on Alki or Pegasus Pizza & Pasta.\n",
      "\n",
      "2:00 PM - Drive about 1.5 hours east of Seattle to the Snoqualmie River for a white water rafting adventure. This will take up the majority of your afternoon.\n",
      "\n",
      "5:30 PM - Return to Seattle after your rafting trip. Head to Lake Union and visit the Center for Wooden Boats, taking a guided boat tour to learn about the city's maritime history.\n",
      "\n",
      "7:00 PM - End your day with dinner at one of the restaurants along the Lake Union waterfront, such as Duke's Seafood & Chowder or Ivar's Salmon House.\n",
      "\n",
      "Please note that adding the white water rafting activity has made the itinerary quite full. Depending on the length and intensity of the rafting trip, you may need to adjust the timing or skip one of the other activities. Let me know if you would like me to modify the plan further.\n"
     ]
    }
   ],
   "source": [
    "user_request = \"Can you add white water rafting to this itinerary\"\n",
    "run_travel_planner(user_request, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Management tools from Langmem.\n",
    "\n",
    "LangMem has released new memory management features which is a complete memory SDK which includes all the types of memory semantic, procedural, entity).\n",
    "\n",
    "[LangMem](https://langchain-ai.github.io/langmem/hot_path_quickstart/#prerequisites)\n",
    "\n",
    "[Langmem memory management](https://langchain-ai.github.io/langmem/reference/memory/#langmem.create_memory_store_manager)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langmem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have successfully executed a simple LangGraph implementation, this lab demonstrates how LangGraph can be used to create a simple yet effective Travel Planner. By structuring our application as a graph of interconnected nodes, we achieve a clear separation of concerns and a easily modifiable workflow. This approach can be extended to more complex applications, showcasing the power and flexibility of graph-based designs in AI-driven conversational interfaces.\n",
    "\n",
    "Please proceed to the next lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lang mem concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - set your credentials if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us examine the 2 critical building blocks for Langmem\n",
    "\n",
    "1. MemoryStoreManager\n",
    "2. MemoryManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.base import BaseStore, Item, Op, Result\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from typing import Any, Iterable, Literal, NamedTuple, Optional, Union, cast\n",
    "\n",
    "class CustomMemoryStore(BaseStore):\n",
    "\n",
    "    def __init__(self, ext_store):\n",
    "        self.store = ext_store\n",
    "\n",
    "    def get(self, namespace: tuple[str, ...], key: str) -> Optional[Item]:\n",
    "        return self.store.get(namespace,key)\n",
    "\n",
    "    def put(self, namespace: tuple[str, ...], key: str, value: dict[str, Any]) -> None:\n",
    "        print(f\"PUT::namespace={namespace}, key={key}, value={value}:\")\n",
    "        return self.store.put(namespace, key, value)\n",
    "    async def aget(self, namespace: tuple[str, ...], key: str) -> Optional[Item]:\n",
    "        res = await self.get(namespace,key)\n",
    "        return res\n",
    "    async def aput(self, namespace: tuple[str, ...], key: str, value: dict[str, Any]) -> None:\n",
    "        res = self.put(namespace, key, value) # cannot await this as this returns a none and also is a sync function\n",
    "        print(f\"ASYN-PUT::::namespace={namespace}, key={key}, value={value}:\")\n",
    "        return None\n",
    "    def batch(self, ops: Iterable[Op]) -> list[Result]:\n",
    "        return self.store.batch(ops)\n",
    "    async def abatch(self, ops: Iterable[Op]) -> list[Result]:\n",
    "        print(f\"ASYNC::BATCH::::ops={ops}:\")\n",
    "        res = await self.store.abatch(ops)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUT::namespace=('chat', 'user123', 'triples'), key=ac65cb2a-eb0e-4c68-8bd3-7ea60978da88, value={'kind': 'Triple', 'content': {'subject': 'Alice', 'predicate': 'manages', 'object': 'ML team', 'context': None}}:PUT::namespace=('chat', 'user123', 'triples'), key=460fe177-274b-422a-b642-1283648fc977, value={'kind': 'Triple', 'content': {'subject': 'Alice', 'predicate': 'mentors', 'object': 'Bob', 'context': None}}:\n",
      "\n",
      "PUT::namespace=('chat', 'user123', 'triples'), key=0ece680e-48ed-4f39-aa76-f7db81a05ec5, value={'kind': 'Triple', 'content': {'subject': 'Bob', 'predicate': 'is_on', 'object': 'ML team', 'context': None}}:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Okay, got it. Alice is the manager of the ML (machine learning) team, and she mentors Bob, who is also a member of the same ML team.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '08442a32-f17c-427f-8d3e-3584546b18e9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 06:53:35 GMT', 'content-type': 'application/json', 'content-length': '313', 'connection': 'keep-alive', 'x-amzn-requestid': '08442a32-f17c-427f-8d3e-3584546b18e9'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [494]}}, id='run-5eff72ae-717b-49a4-b2d7-766e14a22c40-0', usage_metadata={'input_tokens': 30, 'output_tokens': 39, 'total_tokens': 69})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.func import entrypoint\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langmem import create_memory_store_manager\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import ChatBedrock\n",
    "import boto3\n",
    "from IPython.display import Image, display\n",
    "from langmem import create_memory_manager # \n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Triple(BaseModel): # \n",
    "    \"\"\"Store all new facts, preferences, and relationships as triples.\"\"\"\n",
    "    subject: str\n",
    "    predicate: str\n",
    "    object: str\n",
    "    context: str | None = None\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore())\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "memory_manager = create_memory_store_manager(\n",
    "    llm,\n",
    "    namespace=(\"chat\", \"{user_id}\", \"triples\"),\n",
    "    schemas=[Triple],\n",
    "    instructions=\"Extract all user information and events as triples.\",\n",
    "    enable_inserts=True,\n",
    "    enable_deletes=True,\n",
    ")\n",
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice manages the ML team and mentors Bob, who is also on the team.\",\n",
    "        },\n",
    "]\n",
    "#- Will not work - needs a RunnableContext\n",
    "#- raise RuntimeError(\"Called get_config outside of a runnable context\")\n",
    "#- memory_manager.invoke({\"messages\": messages}) \n",
    "\n",
    "# Define app with store context\n",
    "@entrypoint(store=in_memory_store) # \n",
    "def app(messages: list):\n",
    "    response = llm.invoke(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            *messages\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Extract and store triples (Uses store from @entrypoint context)\n",
    "    memory_manager.invoke({\"messages\": messages}) \n",
    "    return response\n",
    "\n",
    "app.invoke(messages, config={\"configurable\": {\"user_id\": \"user123\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create_memory _manager which does not use the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExtractedMemory(id='6dd5698a-6c9a-4180-a814-bdf9577d13ec', content=Triple(subject='Alice', predicate='manages', object='ML team', context=None)),\n",
       " ExtractedMemory(id='395aab24-bac8-4f16-beb6-9091bcc8ecf1', content=Triple(subject='Alice', predicate='mentors', object='Bob', context=None)),\n",
       " ExtractedMemory(id='f899b2c6-c723-4f3f-81bc-aae634b1fc94', content=Triple(subject='Bob', predicate='is on', object='ML team', context=None))]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.func import entrypoint\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langmem import create_memory_store_manager\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import ChatBedrock\n",
    "import boto3\n",
    "from IPython.display import Image, display\n",
    "from langmem import create_memory_manager # \n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Triple(BaseModel): # \n",
    "    \"\"\"Store all new facts, preferences, and relationships as triples.\"\"\"\n",
    "    subject: str\n",
    "    predicate: str\n",
    "    object: str\n",
    "    context: str | None = None\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore())\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "memory_manager = create_memory_manager(\n",
    "    llm,\n",
    "    #namespace=(\"chat\", \"{user_id}\", \"triples\"),\n",
    "    schemas=[Triple],\n",
    "    instructions=\"Extract all user information and events as triples.\",\n",
    "    enable_inserts=True,\n",
    "    enable_deletes=True,\n",
    ")\n",
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice manages the ML team and mentors Bob, who is also on the team.\",\n",
    "        },\n",
    "]\n",
    "\n",
    "memory_manager.invoke({\"messages\": messages}) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick start to lang mem using a react agent\n",
    "\n",
    "This uses the Store manager which is used from the context and the config and the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUT::res::namespace=('memories',), key=6dd6e6db-e4a6-4c9e-b3a9-5cdd68117653, value={'content': 'User prefers dark mode'}:\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember that I prefer dark mode.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': 'User prefers dark mode'}, 'id': 'tooluse_JDga5UmbSj64G0mHbcohbg'}]\n",
      "Tool Calls:\n",
      "  manage_memory (tooluse_JDga5UmbSj64G0mHbcohbg)\n",
      " Call ID: tooluse_JDga5UmbSj64G0mHbcohbg\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User prefers dark mode\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "created memory 6dd6e6db-e4a6-4c9e-b3a9-5cdd68117653\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Rationale:\n",
      "The user has indicated that they prefer dark mode. To remember this preference, I have created a new memory with the content \"User prefers dark mode\". This will allow me to recall this preference in future interactions and tailor the interface accordingly.\n",
      "[None, None, None, None]\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are my lighting preferences?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'tool_use', 'name': 'search_memory', 'input': {'query': 'lighting preferences'}, 'id': 'tooluse_T5qUmwagSciOlnGKwkbjMQ'}]\n",
      "Tool Calls:\n",
      "  search_memory (tooluse_T5qUmwagSciOlnGKwkbjMQ)\n",
      " Call ID: tooluse_T5qUmwagSciOlnGKwkbjMQ\n",
      "  Args:\n",
      "    query: lighting preferences\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_memory\n",
      "\n",
      "[{\"namespace\": [\"memories\"], \"key\": \"6dd6e6db-e4a6-4c9e-b3a9-5cdd68117653\", \"value\": {\"content\": \"User prefers dark mode\"}, \"created_at\": \"2025-03-01T01:17:27.096336+00:00\", \"updated_at\": \"2025-03-01T01:17:27.096342+00:00\", \"score\": null}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the search results, the user's lighting preference is dark mode. The rationale for this response is that the search for \"lighting preferences\" returned a memory with the content \"User prefers dark mode\", indicating that the user's preferred lighting setting is dark mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import core components \n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import ChatBedrock\n",
    "import boto3\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore())\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# Create an agent with memory capabilities \n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[\n",
    "        # Memory tools use LangGraph's BaseStore for persistence (4)\n",
    "        create_manage_memory_tool(namespace=(\"memories\",)),\n",
    "        create_search_memory_tool(namespace=(\"memories\",)),\n",
    "    ],\n",
    "    store=in_memory_store,\n",
    "    state_modifier=\"\"\"\n",
    "    For every response output the details of what was the rationale for the response\n",
    "    \"\"\",\n",
    ")\n",
    "# Store a new memory \n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Remember that I prefer dark mode.\"}]}\n",
    ")\n",
    "print([x.pretty_print() for x in response[\"messages\"] ])\n",
    "# Retrieve the stored memory \n",
    "\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What are my lighting preferences?\"}]}\n",
    ")\n",
    "#print(response[\"messages\"][-1].content)\n",
    "[x.pretty_print() for x in response[\"messages\"] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('memories',)]\n",
      "[Item(namespace=['memories'], key='6dd6e6db-e4a6-4c9e-b3a9-5cdd68117653', value={'content': 'User prefers dark mode'}, created_at='2025-03-01T01:17:27.096336+00:00', updated_at='2025-03-01T01:17:27.096342+00:00', score=None)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {('memories',): {'6dd6e6db-e4a6-4c9e-b3a9-5cdd68117653': Item(namespace=['memories'], key='6dd6e6db-e4a6-4c9e-b3a9-5cdd68117653', value={'content': 'User prefers dark mode'}, created_at='2025-03-01T01:17:27.096336+00:00', updated_at='2025-03-01T01:17:27.096342+00:00')}})"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#- {'3f8125d8-f922-4672-b88c-9a369f7e61c6': Item(namespace=['memories'], key='3f8125d8-f922-4672-b88c-9a369f7e61c6', value={'content': 'The user prefers dark mode.'}, created_at='2025-02-25T19:58:57.511231+00:00', updated_at='2025-02-25T19:58:57.511234+00:00')}\n",
    "#- in_memory_store.store._data[('memories',)]\n",
    "namespace_u = ('memories',)\n",
    "key_u='289a2f0e-f9dc-461e-b257-a7d221d288c3'\n",
    "#item_u = in_memory_store.get(namespace_u, key_u)\n",
    "#print(item_u.value, item_u.value['data'])\n",
    "\n",
    "print(in_memory_store.store.list_namespaces())\n",
    "print(in_memory_store.store.search((\"memories\",)))\n",
    "in_memory_store.store._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we wil review the concept of \n",
    "1. Populating the Memory with every turn by turnby turn conversation\n",
    "2. Or updating it Peridically "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the condition for managing for multiple users for turn by  turn\n",
    "1. User A having memory defined and so the agents is able to review and get that \n",
    "2. user B not having any memory and the agent returns `non hallucinated` answer\n",
    "\n",
    "we will the `store` put being called multiple times as the memory gets updates. The create_store_manager uses a get_store() call which in turn calls the context and State object to tget the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt::state is {'messages': [HumanMessage(content='Know which display mode I prefer?', additional_kwargs={}, response_metadata={}, id='fa674616-6a71-4c46-bd94-6d202985be86')], 'is_last_step': False, 'remaining_steps': 24}:\n",
      "PUT::res::namespace=('memories',), key=47a71c61-b652-4ce6-8778-c54124803c4f, value={'content': 'User display mode preference'}:\n",
      "prompt::state is {'messages': [HumanMessage(content='Know which display mode I prefer?', additional_kwargs={}, response_metadata={}, id='fa674616-6a71-4c46-bd94-6d202985be86'), AIMessage(content=[{'type': 'text', 'text': \"I'm afraid I don't have any information about your display mode preferences stored in my memory. As an AI assistant, I don't have any pre-existing knowledge about your personal preferences unless you've explicitly provided that information to me before.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '18e64343-923c-4031-8615-73ec60136c9d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:00 GMT', 'content-type': 'application/json', 'content-length': '589', 'connection': 'keep-alive', 'x-amzn-requestid': '18e64343-923c-4031-8615-73ec60136c9d'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1583]}}, id='run-bd6a9a6c-26b1-423a-a14b-21331a6c3220-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w', 'type': 'tool_call'}], usage_metadata={'input_tokens': 534, 'output_tokens': 122, 'total_tokens': 656}), ToolMessage(content='created memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='b5433c59-2361-4bc6-9d81-a49079590d74', tool_call_id='tooluse_skAf4UjwQsioHhDVc-vu7w')], 'is_last_step': False, 'remaining_steps': 22}:\n",
      "I've now created a new memory entry to track your display mode preference. In the future, if you let me know your preferred display mode, I can store that information and recall it when you ask. Please feel free to provide your display mode preference, and I'll be happy to update my memory.\n",
      "prompt::state is {'messages': [HumanMessage(content='Know which display mode I prefer?', additional_kwargs={}, response_metadata={}, id='fa674616-6a71-4c46-bd94-6d202985be86'), AIMessage(content=[{'type': 'text', 'text': \"I'm afraid I don't have any information about your display mode preferences stored in my memory. As an AI assistant, I don't have any pre-existing knowledge about your personal preferences unless you've explicitly provided that information to me before.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '18e64343-923c-4031-8615-73ec60136c9d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:00 GMT', 'content-type': 'application/json', 'content-length': '589', 'connection': 'keep-alive', 'x-amzn-requestid': '18e64343-923c-4031-8615-73ec60136c9d'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1583]}}, id='run-bd6a9a6c-26b1-423a-a14b-21331a6c3220-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w', 'type': 'tool_call'}], usage_metadata={'input_tokens': 534, 'output_tokens': 122, 'total_tokens': 656}), ToolMessage(content='created memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='b5433c59-2361-4bc6-9d81-a49079590d74', tool_call_id='tooluse_skAf4UjwQsioHhDVc-vu7w'), AIMessage(content=\"I've now created a new memory entry to track your display mode preference. In the future, if you let me know your preferred display mode, I can store that information and recall it when you ask. Please feel free to provide your display mode preference, and I'll be happy to update my memory.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '6023b20b-244d-4658-8bb9-2807b6f178f9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:01 GMT', 'content-type': 'application/json', 'content-length': '475', 'connection': 'keep-alive', 'x-amzn-requestid': '6023b20b-244d-4658-8bb9-2807b6f178f9'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1249]}}, id='run-508adc27-9ede-4a3f-a6ab-3917a6ffa5e2-0', usage_metadata={'input_tokens': 789, 'output_tokens': 65, 'total_tokens': 854}), HumanMessage(content='dark. Remember that.', additional_kwargs={}, response_metadata={}, id='1ce41195-1fc1-46d4-a2b3-bd48762ee843')], 'is_last_step': False, 'remaining_steps': 24}:\n",
      "PUT::res::namespace=('memories',), key=47a71c61-b652-4ce6-8778-c54124803c4f, value={'content': 'dark'}:\n",
      "prompt::state is {'messages': [HumanMessage(content='Know which display mode I prefer?', additional_kwargs={}, response_metadata={}, id='fa674616-6a71-4c46-bd94-6d202985be86'), AIMessage(content=[{'type': 'text', 'text': \"I'm afraid I don't have any information about your display mode preferences stored in my memory. As an AI assistant, I don't have any pre-existing knowledge about your personal preferences unless you've explicitly provided that information to me before.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '18e64343-923c-4031-8615-73ec60136c9d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:00 GMT', 'content-type': 'application/json', 'content-length': '589', 'connection': 'keep-alive', 'x-amzn-requestid': '18e64343-923c-4031-8615-73ec60136c9d'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1583]}}, id='run-bd6a9a6c-26b1-423a-a14b-21331a6c3220-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w', 'type': 'tool_call'}], usage_metadata={'input_tokens': 534, 'output_tokens': 122, 'total_tokens': 656}), ToolMessage(content='created memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='b5433c59-2361-4bc6-9d81-a49079590d74', tool_call_id='tooluse_skAf4UjwQsioHhDVc-vu7w'), AIMessage(content=\"I've now created a new memory entry to track your display mode preference. In the future, if you let me know your preferred display mode, I can store that information and recall it when you ask. Please feel free to provide your display mode preference, and I'll be happy to update my memory.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '6023b20b-244d-4658-8bb9-2807b6f178f9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:01 GMT', 'content-type': 'application/json', 'content-length': '475', 'connection': 'keep-alive', 'x-amzn-requestid': '6023b20b-244d-4658-8bb9-2807b6f178f9'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1249]}}, id='run-508adc27-9ede-4a3f-a6ab-3917a6ffa5e2-0', usage_metadata={'input_tokens': 789, 'output_tokens': 65, 'total_tokens': 854}), HumanMessage(content='dark. Remember that.', additional_kwargs={}, response_metadata={}, id='1ce41195-1fc1-46d4-a2b3-bd48762ee843'), AIMessage(content=[{'type': 'text', 'text': \"Okay, got it. I've updated the memory to reflect your preference for a dark display mode.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '26355f3c-061c-462f-a5ab-c2ddb6894f81', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:03 GMT', 'content-type': 'application/json', 'content-length': '445', 'connection': 'keep-alive', 'x-amzn-requestid': '26355f3c-061c-462f-a5ab-c2ddb6894f81'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1406]}}, id='run-0e2e0bc7-3942-4ba7-8361-5c0c4d4e9a11-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 862, 'output_tokens': 131, 'total_tokens': 993}), ToolMessage(content='updated memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='f61f5576-6707-4e4a-8962-9d844dd44a5a', tool_call_id='tooluse_1iGIepA2TbOOvWJkVxMlXw')], 'is_last_step': False, 'remaining_steps': 22}:\n",
      "defaultdict(<class 'dict'>, {('memories',): {'47a71c61-b652-4ce6-8778-c54124803c4f': Item(namespace=['memories'], key='47a71c61-b652-4ce6-8778-c54124803c4f', value={'content': 'dark'}, created_at='2025-03-01T01:20:03.072892+00:00', updated_at='2025-03-01T01:20:03.072906+00:00')}})\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Know which display mode I prefer?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"I'm afraid I don't have any information about your display mode preferences stored in my memory. As an AI assistant, I don't have any pre-existing knowledge about your personal preferences unless you've explicitly provided that information to me before.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w'}]\n",
      "Tool Calls:\n",
      "  manage_memory (tooluse_skAf4UjwQsioHhDVc-vu7w)\n",
      " Call ID: tooluse_skAf4UjwQsioHhDVc-vu7w\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User display mode preference\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "created memory 47a71c61-b652-4ce6-8778-c54124803c4f\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've now created a new memory entry to track your display mode preference. In the future, if you let me know your preferred display mode, I can store that information and recall it when you ask. Please feel free to provide your display mode preference, and I'll be happy to update my memory.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "dark. Remember that.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"Okay, got it. I've updated the memory to reflect your preference for a dark display mode.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw'}]\n",
      "Tool Calls:\n",
      "  manage_memory (tooluse_1iGIepA2TbOOvWJkVxMlXw)\n",
      " Call ID: tooluse_1iGIepA2TbOOvWJkVxMlXw\n",
      "  Args:\n",
      "    action: update\n",
      "    id: 47a71c61-b652-4ce6-8778-c54124803c4f\n",
      "    content: dark\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "updated memory 47a71c61-b652-4ce6-8778-c54124803c4f\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've now updated the existing memory to reflect your preference for a dark display mode. I'll be sure to remember this going forward.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.utils.config import get_store \n",
    "from langmem import (\n",
    "    # Lets agent create, update, and delete memories \n",
    "    create_manage_memory_tool,\n",
    ")\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "#- can eb a function which gets converted to a Runnablecallable or can eb a ChatPromptTemplate which becomes a System prompt\n",
    "def prompt(state):\n",
    "    \"\"\"Prepare the messages for the LLM.\"\"\"\n",
    "    # Get store from configured contextvar; \n",
    "    print(f\"prompt::state is {state}:\")\n",
    "    store = get_store() # Same as that provided to `create_react_agent`\n",
    "    memories = store.search(\n",
    "        # Search within the same namespace as the one\n",
    "        # we've configured for the agent\n",
    "        (\"memories\",),\n",
    "        query=state[\"messages\"][-1].content,\n",
    "    )\n",
    "    system_msg = f\"\"\"You are a helpful assistant.\n",
    "\n",
    "## Memories\n",
    "<memories>\n",
    "{memories}\n",
    "</memories>\n",
    "\"\"\"\n",
    "    return [{\"role\": \"system\", \"content\": system_msg}, *state[\"messages\"]]\n",
    "\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore()) \n",
    "\n",
    "checkpointer = MemorySaver() # Checkpoint graph state \n",
    "\n",
    "agent = create_react_agent( \n",
    "    llm,\n",
    "    prompt=prompt,\n",
    "    tools=[ # Add memory tools \n",
    "        # The agent can call \"manage_memory\" to\n",
    "        # create, update, and delete memories by ID\n",
    "        # Namespaces add scope to memories. To\n",
    "        # scope memories per-user, do (\"memories\", \"{user_id}\"): \n",
    "        create_manage_memory_tool(namespace=(\"memories\",)),\n",
    "    ],\n",
    "    # Our memories will be stored in this provided BaseStore instance\n",
    "    store=in_memory_store,\n",
    "    # And the graph \"state\" will be checkpointed after each node\n",
    "    # completes executing for tracking the chat history and durable execution\n",
    "    checkpointer=checkpointer, \n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"thread-a\"}}\n",
    "\n",
    "# Use the agent. The agent hasn't saved any memories,\n",
    "# so it doesn't know about us\n",
    "response = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Know which display mode I prefer?\"}\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "print(response[\"messages\"][-1].content)\n",
    "# Output: \"I don't seem to have any stored memories about your display mode preferences...\"\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"dark. Remember that.\"}\n",
    "        ]\n",
    "    },\n",
    "    # We will continue the conversation (thread-a) by using the config with\n",
    "    # the same thread_id\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(in_memory_store.store._data)\n",
    "[x.pretty_print() for x in response[\"messages\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now invoke with a user with no `memory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt::state is {'messages': [HumanMessage(content='Know which display mode I prefer?', additional_kwargs={}, response_metadata={}, id='fa674616-6a71-4c46-bd94-6d202985be86'), AIMessage(content=[{'type': 'text', 'text': \"I'm afraid I don't have any information about your display mode preferences stored in my memory. As an AI assistant, I don't have any pre-existing knowledge about your personal preferences unless you've explicitly provided that information to me before.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '18e64343-923c-4031-8615-73ec60136c9d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:00 GMT', 'content-type': 'application/json', 'content-length': '589', 'connection': 'keep-alive', 'x-amzn-requestid': '18e64343-923c-4031-8615-73ec60136c9d'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1583]}}, id='run-bd6a9a6c-26b1-423a-a14b-21331a6c3220-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w', 'type': 'tool_call'}], usage_metadata={'input_tokens': 534, 'output_tokens': 122, 'total_tokens': 656}), ToolMessage(content='created memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='b5433c59-2361-4bc6-9d81-a49079590d74', tool_call_id='tooluse_skAf4UjwQsioHhDVc-vu7w'), AIMessage(content=\"I've now created a new memory entry to track your display mode preference. In the future, if you let me know your preferred display mode, I can store that information and recall it when you ask. Please feel free to provide your display mode preference, and I'll be happy to update my memory.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '6023b20b-244d-4658-8bb9-2807b6f178f9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:01 GMT', 'content-type': 'application/json', 'content-length': '475', 'connection': 'keep-alive', 'x-amzn-requestid': '6023b20b-244d-4658-8bb9-2807b6f178f9'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1249]}}, id='run-508adc27-9ede-4a3f-a6ab-3917a6ffa5e2-0', usage_metadata={'input_tokens': 789, 'output_tokens': 65, 'total_tokens': 854}), HumanMessage(content='dark. Remember that.', additional_kwargs={}, response_metadata={}, id='1ce41195-1fc1-46d4-a2b3-bd48762ee843'), AIMessage(content=[{'type': 'text', 'text': \"Okay, got it. I've updated the memory to reflect your preference for a dark display mode.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '26355f3c-061c-462f-a5ab-c2ddb6894f81', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:03 GMT', 'content-type': 'application/json', 'content-length': '445', 'connection': 'keep-alive', 'x-amzn-requestid': '26355f3c-061c-462f-a5ab-c2ddb6894f81'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1406]}}, id='run-0e2e0bc7-3942-4ba7-8361-5c0c4d4e9a11-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 862, 'output_tokens': 131, 'total_tokens': 993}), ToolMessage(content='updated memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='f61f5576-6707-4e4a-8962-9d844dd44a5a', tool_call_id='tooluse_1iGIepA2TbOOvWJkVxMlXw'), AIMessage(content=\"I've now updated the existing memory to reflect your preference for a dark display mode. I'll be sure to remember this going forward.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '1042a77c-dfe0-4a12-90ae-cb365ada7fad', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:03 GMT', 'content-type': 'application/json', 'content-length': '318', 'connection': 'keep-alive', 'x-amzn-requestid': '1042a77c-dfe0-4a12-90ae-cb365ada7fad'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [874]}}, id='run-28d57f3b-ff02-4364-b188-c5f972d6c190-0', usage_metadata={'input_tokens': 1027, 'output_tokens': 31, 'total_tokens': 1058}), HumanMessage(content='what is my mode preference?', additional_kwargs={}, response_metadata={}, id='9c32d1b0-7e4a-4ec0-9398-7f46f4f20f0f')], 'is_last_step': False, 'remaining_steps': 24}:\n",
      "prompt::state is {'messages': [HumanMessage(content='Know which display mode I prefer?', additional_kwargs={}, response_metadata={}, id='fa674616-6a71-4c46-bd94-6d202985be86'), AIMessage(content=[{'type': 'text', 'text': \"I'm afraid I don't have any information about your display mode preferences stored in my memory. As an AI assistant, I don't have any pre-existing knowledge about your personal preferences unless you've explicitly provided that information to me before.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '18e64343-923c-4031-8615-73ec60136c9d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:00 GMT', 'content-type': 'application/json', 'content-length': '589', 'connection': 'keep-alive', 'x-amzn-requestid': '18e64343-923c-4031-8615-73ec60136c9d'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1583]}}, id='run-bd6a9a6c-26b1-423a-a14b-21331a6c3220-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w', 'type': 'tool_call'}], usage_metadata={'input_tokens': 534, 'output_tokens': 122, 'total_tokens': 656}), ToolMessage(content='created memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='b5433c59-2361-4bc6-9d81-a49079590d74', tool_call_id='tooluse_skAf4UjwQsioHhDVc-vu7w'), AIMessage(content=\"I've now created a new memory entry to track your display mode preference. In the future, if you let me know your preferred display mode, I can store that information and recall it when you ask. Please feel free to provide your display mode preference, and I'll be happy to update my memory.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '6023b20b-244d-4658-8bb9-2807b6f178f9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:01 GMT', 'content-type': 'application/json', 'content-length': '475', 'connection': 'keep-alive', 'x-amzn-requestid': '6023b20b-244d-4658-8bb9-2807b6f178f9'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1249]}}, id='run-508adc27-9ede-4a3f-a6ab-3917a6ffa5e2-0', usage_metadata={'input_tokens': 789, 'output_tokens': 65, 'total_tokens': 854}), HumanMessage(content='dark. Remember that.', additional_kwargs={}, response_metadata={}, id='1ce41195-1fc1-46d4-a2b3-bd48762ee843'), AIMessage(content=[{'type': 'text', 'text': \"Okay, got it. I've updated the memory to reflect your preference for a dark display mode.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '26355f3c-061c-462f-a5ab-c2ddb6894f81', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:03 GMT', 'content-type': 'application/json', 'content-length': '445', 'connection': 'keep-alive', 'x-amzn-requestid': '26355f3c-061c-462f-a5ab-c2ddb6894f81'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1406]}}, id='run-0e2e0bc7-3942-4ba7-8361-5c0c4d4e9a11-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 862, 'output_tokens': 131, 'total_tokens': 993}), ToolMessage(content='updated memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='f61f5576-6707-4e4a-8962-9d844dd44a5a', tool_call_id='tooluse_1iGIepA2TbOOvWJkVxMlXw'), AIMessage(content=\"I've now updated the existing memory to reflect your preference for a dark display mode. I'll be sure to remember this going forward.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '1042a77c-dfe0-4a12-90ae-cb365ada7fad', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:03 GMT', 'content-type': 'application/json', 'content-length': '318', 'connection': 'keep-alive', 'x-amzn-requestid': '1042a77c-dfe0-4a12-90ae-cb365ada7fad'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [874]}}, id='run-28d57f3b-ff02-4364-b188-c5f972d6c190-0', usage_metadata={'input_tokens': 1027, 'output_tokens': 31, 'total_tokens': 1058}), HumanMessage(content='what is my mode preference?', additional_kwargs={}, response_metadata={}, id='9c32d1b0-7e4a-4ec0-9398-7f46f4f20f0f'), AIMessage(content=[{'type': 'text', 'text': 'Let me check the memory I have stored about your display mode preference:'}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'id': '47a71c61-b652-4ce6-8778-c54124803c4f'}, 'id': 'tooluse_9AA78eE0RJ2DcHi7qP5GzA'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '34746857-412a-4603-8828-37cdb3f35043', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:06 GMT', 'content-type': 'application/json', 'content-length': '395', 'connection': 'keep-alive', 'x-amzn-requestid': '34746857-412a-4603-8828-37cdb3f35043'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1108]}}, id='run-eb373854-830b-4152-a9dc-aea1babe49ad-0', tool_calls=[{'name': 'manage_memory', 'args': {'id': '47a71c61-b652-4ce6-8778-c54124803c4f'}, 'id': 'tooluse_9AA78eE0RJ2DcHi7qP5GzA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1067, 'output_tokens': 90, 'total_tokens': 1157}), ToolMessage(content=\"Error: ValueError('You cannot provide a MEMORY ID when creating a MEMORY. Please try again, omitting the id argument.')\\n Please fix your mistakes.\", name='manage_memory', id='725d732d-d9cc-4374-81bc-21743984382b', tool_call_id='tooluse_9AA78eE0RJ2DcHi7qP5GzA', status='error')], 'is_last_step': False, 'remaining_steps': 22}:\n",
      "PUT::res::namespace=('memories',), key=f21ceeb5-9326-418d-a7c4-02d2a7cb5614, value={'content': None}:\n",
      "prompt::state is {'messages': [HumanMessage(content='Know which display mode I prefer?', additional_kwargs={}, response_metadata={}, id='fa674616-6a71-4c46-bd94-6d202985be86'), AIMessage(content=[{'type': 'text', 'text': \"I'm afraid I don't have any information about your display mode preferences stored in my memory. As an AI assistant, I don't have any pre-existing knowledge about your personal preferences unless you've explicitly provided that information to me before.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '18e64343-923c-4031-8615-73ec60136c9d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:00 GMT', 'content-type': 'application/json', 'content-length': '589', 'connection': 'keep-alive', 'x-amzn-requestid': '18e64343-923c-4031-8615-73ec60136c9d'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1583]}}, id='run-bd6a9a6c-26b1-423a-a14b-21331a6c3220-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w', 'type': 'tool_call'}], usage_metadata={'input_tokens': 534, 'output_tokens': 122, 'total_tokens': 656}), ToolMessage(content='created memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='b5433c59-2361-4bc6-9d81-a49079590d74', tool_call_id='tooluse_skAf4UjwQsioHhDVc-vu7w'), AIMessage(content=\"I've now created a new memory entry to track your display mode preference. In the future, if you let me know your preferred display mode, I can store that information and recall it when you ask. Please feel free to provide your display mode preference, and I'll be happy to update my memory.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '6023b20b-244d-4658-8bb9-2807b6f178f9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:01 GMT', 'content-type': 'application/json', 'content-length': '475', 'connection': 'keep-alive', 'x-amzn-requestid': '6023b20b-244d-4658-8bb9-2807b6f178f9'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1249]}}, id='run-508adc27-9ede-4a3f-a6ab-3917a6ffa5e2-0', usage_metadata={'input_tokens': 789, 'output_tokens': 65, 'total_tokens': 854}), HumanMessage(content='dark. Remember that.', additional_kwargs={}, response_metadata={}, id='1ce41195-1fc1-46d4-a2b3-bd48762ee843'), AIMessage(content=[{'type': 'text', 'text': \"Okay, got it. I've updated the memory to reflect your preference for a dark display mode.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '26355f3c-061c-462f-a5ab-c2ddb6894f81', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:03 GMT', 'content-type': 'application/json', 'content-length': '445', 'connection': 'keep-alive', 'x-amzn-requestid': '26355f3c-061c-462f-a5ab-c2ddb6894f81'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1406]}}, id='run-0e2e0bc7-3942-4ba7-8361-5c0c4d4e9a11-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 862, 'output_tokens': 131, 'total_tokens': 993}), ToolMessage(content='updated memory 47a71c61-b652-4ce6-8778-c54124803c4f', name='manage_memory', id='f61f5576-6707-4e4a-8962-9d844dd44a5a', tool_call_id='tooluse_1iGIepA2TbOOvWJkVxMlXw'), AIMessage(content=\"I've now updated the existing memory to reflect your preference for a dark display mode. I'll be sure to remember this going forward.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '1042a77c-dfe0-4a12-90ae-cb365ada7fad', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:03 GMT', 'content-type': 'application/json', 'content-length': '318', 'connection': 'keep-alive', 'x-amzn-requestid': '1042a77c-dfe0-4a12-90ae-cb365ada7fad'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [874]}}, id='run-28d57f3b-ff02-4364-b188-c5f972d6c190-0', usage_metadata={'input_tokens': 1027, 'output_tokens': 31, 'total_tokens': 1058}), HumanMessage(content='what is my mode preference?', additional_kwargs={}, response_metadata={}, id='9c32d1b0-7e4a-4ec0-9398-7f46f4f20f0f'), AIMessage(content=[{'type': 'text', 'text': 'Let me check the memory I have stored about your display mode preference:'}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'id': '47a71c61-b652-4ce6-8778-c54124803c4f'}, 'id': 'tooluse_9AA78eE0RJ2DcHi7qP5GzA'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '34746857-412a-4603-8828-37cdb3f35043', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:06 GMT', 'content-type': 'application/json', 'content-length': '395', 'connection': 'keep-alive', 'x-amzn-requestid': '34746857-412a-4603-8828-37cdb3f35043'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1108]}}, id='run-eb373854-830b-4152-a9dc-aea1babe49ad-0', tool_calls=[{'name': 'manage_memory', 'args': {'id': '47a71c61-b652-4ce6-8778-c54124803c4f'}, 'id': 'tooluse_9AA78eE0RJ2DcHi7qP5GzA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1067, 'output_tokens': 90, 'total_tokens': 1157}), ToolMessage(content=\"Error: ValueError('You cannot provide a MEMORY ID when creating a MEMORY. Please try again, omitting the id argument.')\\n Please fix your mistakes.\", name='manage_memory', id='725d732d-d9cc-4374-81bc-21743984382b', tool_call_id='tooluse_9AA78eE0RJ2DcHi7qP5GzA', status='error'), AIMessage(content=[{'type': 'text', 'text': 'Oops, my apologies. Let me try that again without specifying the memory ID:'}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create'}, 'id': 'tooluse_SA1xAp8ZTCq6vL0UMU7GTg'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '1ada8e35-0daf-4c66-9d6c-2023729e839b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:07 GMT', 'content-type': 'application/json', 'content-length': '371', 'connection': 'keep-alive', 'x-amzn-requestid': '1ada8e35-0daf-4c66-9d6c-2023729e839b'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1121]}}, id='run-5f98edd4-d05a-4280-af3f-da875dfe35f4-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'create'}, 'id': 'tooluse_SA1xAp8ZTCq6vL0UMU7GTg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1201, 'output_tokens': 75, 'total_tokens': 1276}), ToolMessage(content='created memory f21ceeb5-9326-418d-a7c4-02d2a7cb5614', name='manage_memory', id='25048694-05f5-4f2c-b606-f6d933df97ed', tool_call_id='tooluse_SA1xAp8ZTCq6vL0UMU7GTg')], 'is_last_step': False, 'remaining_steps': 20}:\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Know which display mode I prefer?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"I'm afraid I don't have any information about your display mode preferences stored in my memory. As an AI assistant, I don't have any pre-existing knowledge about your personal preferences unless you've explicitly provided that information to me before.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': 'User display mode preference'}, 'id': 'tooluse_skAf4UjwQsioHhDVc-vu7w'}]\n",
      "Tool Calls:\n",
      "  manage_memory (tooluse_skAf4UjwQsioHhDVc-vu7w)\n",
      " Call ID: tooluse_skAf4UjwQsioHhDVc-vu7w\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User display mode preference\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "created memory 47a71c61-b652-4ce6-8778-c54124803c4f\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've now created a new memory entry to track your display mode preference. In the future, if you let me know your preferred display mode, I can store that information and recall it when you ask. Please feel free to provide your display mode preference, and I'll be happy to update my memory.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "dark. Remember that.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"Okay, got it. I've updated the memory to reflect your preference for a dark display mode.\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'update', 'id': '47a71c61-b652-4ce6-8778-c54124803c4f', 'content': 'dark'}, 'id': 'tooluse_1iGIepA2TbOOvWJkVxMlXw'}]\n",
      "Tool Calls:\n",
      "  manage_memory (tooluse_1iGIepA2TbOOvWJkVxMlXw)\n",
      " Call ID: tooluse_1iGIepA2TbOOvWJkVxMlXw\n",
      "  Args:\n",
      "    action: update\n",
      "    id: 47a71c61-b652-4ce6-8778-c54124803c4f\n",
      "    content: dark\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "updated memory 47a71c61-b652-4ce6-8778-c54124803c4f\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've now updated the existing memory to reflect your preference for a dark display mode. I'll be sure to remember this going forward.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is my mode preference?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Let me check the memory I have stored about your display mode preference:'}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'id': '47a71c61-b652-4ce6-8778-c54124803c4f'}, 'id': 'tooluse_9AA78eE0RJ2DcHi7qP5GzA'}]\n",
      "Tool Calls:\n",
      "  manage_memory (tooluse_9AA78eE0RJ2DcHi7qP5GzA)\n",
      " Call ID: tooluse_9AA78eE0RJ2DcHi7qP5GzA\n",
      "  Args:\n",
      "    id: 47a71c61-b652-4ce6-8778-c54124803c4f\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "Error: ValueError('You cannot provide a MEMORY ID when creating a MEMORY. Please try again, omitting the id argument.')\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Oops, my apologies. Let me try that again without specifying the memory ID:'}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create'}, 'id': 'tooluse_SA1xAp8ZTCq6vL0UMU7GTg'}]\n",
      "Tool Calls:\n",
      "  manage_memory (tooluse_SA1xAp8ZTCq6vL0UMU7GTg)\n",
      " Call ID: tooluse_SA1xAp8ZTCq6vL0UMU7GTg\n",
      "  Args:\n",
      "    action: create\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "created memory f21ceeb5-9326-418d-a7c4-02d2a7cb5614\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "According to the memory I have stored, your preferred display mode is 'dark'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"what is my mode preference?\"}\n",
    "        ]\n",
    "    },\n",
    "    # We will continue the conversation (thread-a) by using the config with\n",
    "    # the same thread_id\n",
    "    config=config,\n",
    ")\n",
    "[x.pretty_print() for x in response[\"messages\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt::state is {'messages': [HumanMessage(content='Hey there. Do you remember me? What are my preferences?', additional_kwargs={}, response_metadata={}, id='582a57dd-d9f8-40d8-ad66-5d06b511b4ff')], 'is_last_step': False, 'remaining_steps': 24}:\n",
      "prompt::state is {'messages': [HumanMessage(content='Hey there. Do you remember me? What are my preferences?', additional_kwargs={}, response_metadata={}, id='582a57dd-d9f8-40d8-ad66-5d06b511b4ff'), AIMessage(content=[{'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'read'}, 'id': 'tooluse_mvjJD6UlQsOKiw8QAvTUlw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '4f9d582f-2291-4fb5-b786-ca166e66f4d6', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:20:14 GMT', 'content-type': 'application/json', 'content-length': '279', 'connection': 'keep-alive', 'x-amzn-requestid': '4f9d582f-2291-4fb5-b786-ca166e66f4d6'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [853]}}, id='run-57af5905-5888-4b6a-8305-22322595cd9f-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'read'}, 'id': 'tooluse_mvjJD6UlQsOKiw8QAvTUlw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 725, 'output_tokens': 53, 'total_tokens': 778}), ToolMessage(content=\"Error: 1 validation error for manage_memory\\naction\\n  Input should be 'create', 'update' or 'delete' [type=literal_error, input_value='read', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.9/v/literal_error\\n Please fix your mistakes.\", name='manage_memory', id='011396c1-09b9-4c38-b54c-c0d7d816811f', tool_call_id='tooluse_mvjJD6UlQsOKiw8QAvTUlw', status='error')], 'is_last_step': False, 'remaining_steps': 22}:\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hey there. Do you remember me? What are my preferences?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'read'}, 'id': 'tooluse_mvjJD6UlQsOKiw8QAvTUlw'}]\n",
      "Tool Calls:\n",
      "  manage_memory (tooluse_mvjJD6UlQsOKiw8QAvTUlw)\n",
      " Call ID: tooluse_mvjJD6UlQsOKiw8QAvTUlw\n",
      "  Args:\n",
      "    action: read\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "Error: 1 validation error for manage_memory\n",
      "action\n",
      "  Input should be 'create', 'update' or 'delete' [type=literal_error, input_value='read', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/literal_error\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Apologies, I don't have any specific preferences stored for you yet. As an AI assistant, I don't have a persistent memory of our previous conversations or your personal preferences. Could you please let me know if there are any preferences you'd like me to remember for you? I'd be happy to store that information so I can better assist you going forward.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New thread = new conversation!\n",
    "new_config = {\"configurable\": {\"thread_id\": \"thread-b\"}}\n",
    "# The agent will only be able to recall\n",
    "# whatever it explicitly saved using the manage_memories tool\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hey there. Do you remember me? What are my preferences?\"}]},\n",
    "    config=new_config,\n",
    ")\n",
    "#print(response[\"messages\"][-1].content)\n",
    "[x.pretty_print() for x in response[\"messages\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Optimizers using Bedrock and Langmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'research', 'prompt': 'Provide a detailed overview of the solar system, including:\\n\\nIntroduction\\n- Brief description of the solar system and its place in the universe\\n\\nKey Components\\n- The sun and its role as the center of the solar system\\n- The 8 major planets (Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune)\\n- Moons, asteroids, comets, and other notable features\\n\\nDescriptions of Each Component\\n- For each planet, describe its size, composition, orbit, and any unique characteristics\\n- Highlight key facts about the sun, moons, asteroids, etc.\\n\\nConclusion\\n- Summarize the overall structure and scale of the solar system\\n\\nPlease let me know if you need any clarification or have additional details you would like me to include.'}, {'name': 'summarize', 'prompt': 'Summarize the research findings'}]\n"
     ]
    }
   ],
   "source": [
    "from langmem import create_multi_prompt_optimizer\n",
    "\n",
    "optimizer = create_multi_prompt_optimizer(llm)\n",
    "\n",
    "# Example conversation with feedback\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about the solar system\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The solar system consists of...\"},\n",
    "]\n",
    "feedback = {\"clarity\": \"needs more structure\"}\n",
    "\n",
    "# Use conversation history to improve the prompts\n",
    "trajectories = [(conversation, feedback)]\n",
    "prompts = [\n",
    "    {\"name\": \"research\", \"prompt\": \"Research the given topic thoroughly\"},\n",
    "    {\"name\": \"summarize\", \"prompt\": \"Summarize the research findings\"},\n",
    "]\n",
    "better_prompts = await optimizer.ainvoke(\n",
    "    {\"trajectories\": trajectories, \"prompts\": prompts}\n",
    ")\n",
    "print(better_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hello World for `asyncio` a quick recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Charlie!::delay=1::res=None\n",
      "Hello, Alice!::delay=4::res=None\n",
      "Hello, Bob!::delay=5::res=None\n",
      "Hello, Bob_2!::delay=5::res=None\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def say_hello(name, delay):\n",
    "    res = await asyncio.sleep(delay)\n",
    "    print(f\"Hello, {name}!::delay={delay}::res={res}\")\n",
    "\n",
    "async def main():\n",
    "    # Run tasks concurrently\n",
    "    await asyncio.gather(\n",
    "        say_hello(\"Alice\", 4),\n",
    "        say_hello(\"Bob\", 5),\n",
    "        say_hello(\"Bob_2\", 5),\n",
    "        say_hello(\"Charlie\", 1)\n",
    "    )\n",
    "    # tasks = [process_and_update(item) for item in items]\n",
    "    # results = await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "\n",
    "# In Jupyter, you can directly await coroutines in a cell since it has it's own event loop\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the `memory` in a-sync for offline memory aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.base import BaseStore, Item, Op, Result\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from typing import Any, Iterable, Literal, NamedTuple, Optional, Union, cast\n",
    "\n",
    "class CustomMemoryStore(BaseStore):\n",
    "\n",
    "    def __init__(self, ext_store):\n",
    "        self.store = ext_store\n",
    "\n",
    "    def get(self, namespace: tuple[str, ...], key: str) -> Optional[Item]:\n",
    "        return self.store.get(namespace,key)\n",
    "\n",
    "    def put(self, namespace: tuple[str, ...], key: str, value: dict[str, Any]) -> None:\n",
    "        print(f\"PUT::namespace={namespace}, key={key}, value={value}:\")\n",
    "        return self.store.put(namespace, key, value)\n",
    "    async def aget(self, namespace: tuple[str, ...], key: str) -> Optional[Item]:\n",
    "        res = await self.get(namespace,key)\n",
    "        return res\n",
    "    async def aput(self, namespace: tuple[str, ...], key: str, value: dict[str, Any]) -> None:\n",
    "        res = self.put(namespace, key, value) # cannot await this as this returns a none and also is a sync function\n",
    "        print(f\"ASYN-PUT::::namespace={namespace}, key={key}, value={value}:\")\n",
    "        return None\n",
    "    def batch(self, ops: Iterable[Op]) -> list[Result]:\n",
    "        return self.store.batch(ops)\n",
    "    async def abatch(self, ops: Iterable[Op]) -> list[Result]:\n",
    "        print(f\"ASYNC::BATCH::::ops={ops}:\")\n",
    "        res = await self.store.abatch(ops)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASYNC::BATCH::::ops=[SearchOp(namespace_prefix=('memories',), filter=None, limit=10, offset=0, query=\"================================== Ai Message ==================================\\n\\nThat's great that you like dogs! Dexter is a nice name for a dog. Dogs can make wonderful companions. What do you enjoy most about having Dexter as a pet?\")]:\n",
      "PUT::namespace=('memories',), key=11a79c24-7ab2-4904-b408-0b427e9ad62c, value={'kind': 'Memory', 'content': {'content': \"The user likes dogs. Their dog's name is Dexter.\"}}:\n",
      "ASYN-PUT::::namespace=('memories',), key=11a79c24-7ab2-4904-b408-0b427e9ad62c, value={'kind': 'Memory', 'content': {'content': \"The user likes dogs. Their dog's name is Dexter.\"}}:\n",
      "That's great that you like dogs! Dexter is a nice name for a dog. Dogs can make wonderful companions. What do you enjoy most about having Dexter as a pet?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.func import entrypoint\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langmem import ReflectionExecutor, create_memory_store_manager\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langmem import ReflectionExecutor, create_memory_store_manager\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore()) \n",
    "#in_memory_store = InMemoryStore()\n",
    "#bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# Create memory manager Runnable to extract memories from conversations\n",
    "memory_manager = create_memory_store_manager(\n",
    "    llm,\n",
    "    # Store memories in the \"memories\" namespace (aka directory)\n",
    "    namespace=(\"memories\",),  # \n",
    ")\n",
    "# Wrap memory_manager to handle deferred background processing \n",
    "executor = ReflectionExecutor(memory_manager)\n",
    "\n",
    "#- does not have chat history so not of much use\n",
    "llm_chat_model = init_chat_model(\"anthropic.claude-3-haiku-20240307-v1:0\", model_provider='bedrock')\n",
    "\n",
    "@entrypoint(store=in_memory_store)  # Create a LangGraph workflow\n",
    "async def chat(message: str):\n",
    "    response = llm.invoke(message)\n",
    "    #response = llm_chat_model.invoke(message)\n",
    "\n",
    "    # memory_manager extracts memories from conversation history\n",
    "    # We'll provide it in OpenAI's message format\n",
    "    to_process = {\"messages\": [{\"role\": \"user\", \"content\": message}] + [response]}\n",
    "    await memory_manager.ainvoke(to_process)  # \n",
    "    return response.content\n",
    "\n",
    "# Run conversation as normal\n",
    "response = await chat.ainvoke(\n",
    "    \"I like dogs. My dog's name is Dexter.\",\n",
    ")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASYNC::BATCH::::ops=[SearchOp(namespace_prefix=('memories',), filter=None, limit=10, offset=0, query=\"================================== Ai Message ==================================\\n\\nHere are some gift ideas you could consider for him:\\n\\n1. Tech gadgets - Things like a new smartphone, smartwatch, wireless headphones, portable charger, etc. are often popular gifts for men.\\n\\n2. Experiences - Tickets to a sporting event, concert, or activity he enjoys like golfing, fishing, or a cooking class.\\n\\n3. Apparel - A nice jacket, shirt, pair of jeans, or accessories like a belt, wallet, or sunglasses.\\n\\n4. Hobby-related gifts - If you know his hobbies, consider getting him something related to that like tools, equipment, books, or supplies.\\n\\n5. Grooming products - High-quality shaving kit, cologne, skincare products, etc.\\n\\n6. Home/office items - A nice desk organizer, coffee table book, home decor piece, or bar accessories.\\n\\n7. Gift cards - If you're unsure, a gift card to his favorite store, restaurant, or online retailer allows him to choose something he'll really like.\\n\\nThe best gift will depend on his personal interests and preferences. Consider his hobbies, style, and needs to pick something thoughtful and meaningful.\")]:\n",
      "PUT::namespace=('memories',), key=1a5c5af3-8edb-4d2b-8c4b-ec47864735c1, value={'kind': 'Memory', 'content': {'content': \"The user is looking for a gift to buy for someone, likely a male. Some potential gift ideas include tech gadgets, experiences, apparel, hobby-related items, grooming products, home/office items, and gift cards. The best gift will depend on the recipient's personal interests and preferences.\"}}:\n",
      "ASYN-PUT::::namespace=('memories',), key=1a5c5af3-8edb-4d2b-8c4b-ec47864735c1, value={'kind': 'Memory', 'content': {'content': \"The user is looking for a gift to buy for someone, likely a male. Some potential gift ideas include tech gadgets, experiences, apparel, hobby-related items, grooming products, home/office items, and gift cards. The best gift will depend on the recipient's personal interests and preferences.\"}}:\n",
      "Here are some gift ideas you could consider for him:\n",
      "\n",
      "1. Tech gadgets - Things like a new smartphone, smartwatch, wireless headphones, portable charger, etc. are often popular gifts for men.\n",
      "\n",
      "2. Experiences - Tickets to a sporting event, concert, or activity he enjoys like golfing, fishing, or a cooking class.\n",
      "\n",
      "3. Apparel - A nice jacket, shirt, pair of jeans, or accessories like a belt, wallet, or sunglasses.\n",
      "\n",
      "4. Hobby-related gifts - If you know his hobbies, consider getting him something related to that like tools, equipment, books, or supplies.\n",
      "\n",
      "5. Grooming products - High-quality shaving kit, cologne, skincare products, etc.\n",
      "\n",
      "6. Home/office items - A nice desk organizer, coffee table book, home decor piece, or bar accessories.\n",
      "\n",
      "7. Gift cards - If you're unsure, a gift card to his favorite store, restaurant, or online retailer allows him to choose something he'll really like.\n",
      "\n",
      "The best gift will depend on his personal interests and preferences. Consider his hobbies, style, and needs to pick something thoughtful and meaningful.\n"
     ]
    }
   ],
   "source": [
    "response = await chat.ainvoke(\n",
    "    \"what gift should i buy for him\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Item(namespace=['memories'], key='11a79c24-7ab2-4904-b408-0b427e9ad62c', value={'kind': 'Memory', 'content': {'content': \"The user likes dogs. Their dog's name is Dexter.\"}}, created_at='2025-03-01T01:23:04.510885+00:00', updated_at='2025-03-01T01:23:04.510887+00:00', score=None), Item(namespace=['memories'], key='1a5c5af3-8edb-4d2b-8c4b-ec47864735c1', value={'kind': 'Memory', 'content': {'content': \"The user is looking for a gift to buy for someone, likely a male. Some potential gift ideas include tech gadgets, experiences, apparel, hobby-related items, grooming products, home/office items, and gift cards. The best gift will depend on the recipient's personal interests and preferences.\"}}, created_at='2025-03-01T01:23:23.049803+00:00', updated_at='2025-03-01T01:23:23.049807+00:00', score=None)]\n"
     ]
    }
   ],
   "source": [
    "print(in_memory_store.search((\"memories\",)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's great that you like dogs! Dexter is a nice name for a dog. Dogs can make wonderful companions. What do you enjoy most about having Dexter as a pet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in local reflection worker: CANCELLED: <Future at 0x30173b690 state=cancelled>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUT::namespace=('memories',), key=33f57324-1f54-43dc-bc43-afbf0f9cecc8, value={'kind': 'Memory', 'content': {'content': 'The user asked for a gift recommendation for someone, indicating they want to buy a gift for this person. This suggests the user cares about the recipient and wants to get them something thoughtful and useful. The user did not provide any additional details about the recipient, so I should provide a range of general gift ideas that could work for different types of people and relationships.'}}:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.func import entrypoint\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langmem import ReflectionExecutor, create_memory_store_manager\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langmem import ReflectionExecutor, create_memory_store_manager\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore()) \n",
    "#in_memory_store = InMemoryStore()\n",
    "#bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# Create memory manager Runnable to extract memories from conversations\n",
    "memory_manager = create_memory_store_manager(\n",
    "    llm,\n",
    "    # Store memories in the \"memories\" namespace (aka directory)\n",
    "    namespace=(\"memories\",),  # \n",
    ")\n",
    "# Wrap memory_manager to handle deferred background processing \n",
    "executor = ReflectionExecutor(memory_manager)\n",
    "\n",
    "#- does not have chat history so not of much use\n",
    "llm_chat_model = init_chat_model(\"anthropic.claude-3-haiku-20240307-v1:0\", model_provider='bedrock')\n",
    "\n",
    "@entrypoint(store=in_memory_store)  # Create a LangGraph workflow\n",
    "async def chat(message: str):\n",
    "    response = llm.invoke(message)\n",
    "    #response = llm_chat_model.invoke(message)\n",
    "\n",
    "    # memory_manager extracts memories from conversation history\n",
    "    # We'll provide it in OpenAI's message format\n",
    "    to_process = {\"messages\": [{\"role\": \"user\", \"content\": message}] + [response]}\n",
    "\n",
    "    # Wait 30 minutes before processing\n",
    "    # If new messages arrive before then:\n",
    "    # 1. Cancel pending processing task\n",
    "    # 2. Reschedule with new messages included\n",
    "    delay = 0.5 # In practice would choose longer (30-60 min)\n",
    "    delay = 30\n",
    "    # depending on app context.\n",
    "    executor.submit(to_process, after_seconds=delay)\n",
    "    #await memory_manager.ainvoke(to_process)  # \n",
    "    return response.content\n",
    "\n",
    "# Run conversation as normal\n",
    "response = await chat.ainvoke(\n",
    "    \"I like dogs. My dog's name is Dexter.\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run right away and you will see the memory not yet populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(in_memory_store.search((\"memories\",)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you run this cell before 30 sec you will that the memory will be just this last message\n",
    "\n",
    "if you run post 30 sec you will both the memories populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some gift ideas that could work well, depending on the person's interests and your relationship:\n",
      "\n",
      "- If they're into a particular hobby or interest, consider getting them something related to that - e.g. a book, tool, accessory, etc. related to their hobby.\n",
      "\n",
      "- Gift cards to their favorite restaurant, coffee shop, or store are always appreciated.\n",
      "\n",
      "- Tech gadgets or accessories like a nice pair of headphones, a portable charger, a smart speaker, etc.\n",
      "\n",
      "- Subscription boxes for things like monthly book/music/snack deliveries.\n",
      "\n",
      "- Tickets to an event, show, or experience they'd enjoy.\n",
      "\n",
      "- A nice bottle of their favorite liquor or wine.\n",
      "\n",
      "- A cozy blanket, robe, or slippers if they like to relax at home.\n",
      "\n",
      "- A grooming/self-care gift set with cologne, aftershave, bath products, etc.\n",
      "\n",
      "- A personalized item like a monogrammed wallet, engraved pen, or custom photo print.\n",
      "\n",
      "The key is to think about their personality, hobbies, and lifestyle to pick something thoughtful and useful for them. It's also a good idea to stay within your budget. Let me know if you need any other gift suggestions!\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "response = await chat.ainvoke(\n",
    "    \"what gift should i buy for him\",\n",
    ")\n",
    "print(response)\n",
    "print(in_memory_store.search((\"memories\",)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run right away -- this should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Item(namespace=['memories'], key='33f57324-1f54-43dc-bc43-afbf0f9cecc8', value={'kind': 'Memory', 'content': {'content': 'The user asked for a gift recommendation for someone, indicating they want to buy a gift for this person. This suggests the user cares about the recipient and wants to get them something thoughtful and useful. The user did not provide any additional details about the recipient, so I should provide a range of general gift ideas that could work for different types of people and relationships.'}}, created_at='2025-03-01T01:24:29.253347+00:00', updated_at='2025-03-01T01:24:29.253349+00:00', score=None)]\n"
     ]
    }
   ],
   "source": [
    "print(in_memory_store.search((\"memories\",)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run after 30 sec and you will the LAST message got added to the Memory but the very first one is no longer part of the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Item(namespace=['memories'], key='33f57324-1f54-43dc-bc43-afbf0f9cecc8', value={'kind': 'Memory', 'content': {'content': 'The user asked for a gift recommendation for someone, indicating they want to buy a gift for this person. This suggests the user cares about the recipient and wants to get them something thoughtful and useful. The user did not provide any additional details about the recipient, so I should provide a range of general gift ideas that could work for different types of people and relationships.'}}, created_at='2025-03-01T01:24:29.253347+00:00', updated_at='2025-03-01T01:24:29.253349+00:00', score=None)]\n"
     ]
    }
   ],
   "source": [
    "print(in_memory_store.search((\"memories\",)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic memories\n",
    "\n",
    "#### Extract using the semantic memories -- Use Pydantic object to extract the Memories\n",
    "The manager simply manages the LLM call.s If we do not pass in exisiting memories - it will not have any context of previous conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After first conversation:\n",
      "ExtractedMemory(id='161b0b6a-e978-43d2-973f-811b31e6ab52', content=Triple(subject='Alice', predicate='manages', object='ML team', context=None))\n",
      "ExtractedMemory(id='ea1a6739-5bfe-430d-82c9-dc5a451de25f', content=Triple(subject='Alice', predicate='mentors', object='Bob', context=None))\n",
      "ExtractedMemory(id='4ba5e911-afc5-4538-bd76-32ff295de08a', content=Triple(subject='Bob', predicate='is on', object='ML team', context=None))\n",
      "After second conversation:\n",
      "ExtractedMemory(id='b327fabe-4e8f-41fc-b3c7-7223d010caf3', content=Triple(subject='Bob', predicate='leads', object='ML team', context='None'))\n",
      "ExtractedMemory(id='54c040b0-ef11-4ed2-8557-b7f432ff5cfe', content=Triple(subject='Bob', predicate='leads', object='NLP project', context='None'))\n",
      "ExtractedMemory(id='161b0b6a-e978-43d2-973f-811b31e6ab52', content=Triple(subject='Alice', predicate='manages', object='ML team', context=None))\n",
      "ExtractedMemory(id='ea1a6739-5bfe-430d-82c9-dc5a451de25f', content=Triple(subject='Alice', predicate='mentors', object='Bob', context=None))\n",
      "ExtractedMemory(id='4ba5e911-afc5-4538-bd76-32ff295de08a', content=Triple(subject='Bob', predicate='is on', object='ML team', context=None))\n",
      "After third conversation:\n",
      "ExtractedMemory(id='88a71040-e990-4c93-bed7-dcab5d1fc4ae', content=Triple(subject='Alice', predicate='left', object='company', context='None'))\n",
      "ExtractedMemory(id='b327fabe-4e8f-41fc-b3c7-7223d010caf3', content=Triple(subject='Bob', predicate='leads', object='ML team', context='None'))\n",
      "ExtractedMemory(id='54c040b0-ef11-4ed2-8557-b7f432ff5cfe', content=Triple(subject='Bob', predicate='leads', object='NLP project', context='None'))\n",
      "ExtractedMemory(id='161b0b6a-e978-43d2-973f-811b31e6ab52', content=Triple(subject='Alice', predicate='manages', object='ML team', context=None))\n",
      "ExtractedMemory(id='ea1a6739-5bfe-430d-82c9-dc5a451de25f', content=Triple(subject='Alice', predicate='mentors', object='Bob', context=None))\n",
      "ExtractedMemory(id='4ba5e911-afc5-4538-bd76-32ff295de08a', content=Triple(subject='Bob', predicate='is on', object='ML team', context=None))\n",
      "After FOURTH conversation: NO PREVIOUS MEMORIES::\n",
      "ExtractedMemory(id='b5629353-21c7-41f7-9093-8a2e4421424e', content=Triple(subject='Alice', predicate='left', object='the company', context='session_0f09c359-e965-40af-b31d-e8abfc86d0cc'))\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.func import entrypoint\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "from langmem import create_memory_manager # \n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Triple(BaseModel): # \n",
    "    \"\"\"Store all new facts, preferences, and relationships as triples.\"\"\"\n",
    "    subject: str\n",
    "    predicate: str\n",
    "    object: str\n",
    "    context: str | None = None\n",
    "\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore()) \n",
    "#in_memory_store = InMemoryStore()\n",
    "#bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# Configure extraction\n",
    "memory_manager = create_memory_manager(  \n",
    "    llm,\n",
    "    schemas=[Triple], \n",
    "    instructions=\"Extract user preferences and any other useful information\",\n",
    "    enable_inserts=True,\n",
    "    enable_deletes=True,\n",
    ")\n",
    "\n",
    "\n",
    "# First conversation - extract triples\n",
    "conversation1 = [\n",
    "    {\"role\": \"user\", \"content\": \"Alice manages the ML team and mentors Bob, who is also on the team.\"}\n",
    "]\n",
    "memories = memory_manager.invoke({\"messages\": conversation1})\n",
    "print(\"After first conversation:\")\n",
    "for m in memories:\n",
    "    print(m)\n",
    "\n",
    "# Second conversation - update and add triples\n",
    "conversation2 = [\n",
    "    {\"role\": \"user\", \"content\": \"Bob now leads the ML team and the NLP project.\"}\n",
    "]\n",
    "update = memory_manager.invoke({\"messages\": conversation2, \"existing\": memories})\n",
    "print(\"After second conversation:\")\n",
    "for m in update:\n",
    "    print(m)\n",
    "\n",
    "# Delete triples about an entity\n",
    "existing = [m for m in update if isinstance(m.content, Triple)]\n",
    "conversation3 = [\n",
    "    {\"role\": \"user\", \"content\": \"Alice left the company.\"}\n",
    "]\n",
    "final = memory_manager.invoke({\"messages\": conversation3, \"existing\": existing})\n",
    "print(\"After third conversation:\")\n",
    "for m in final:\n",
    "    print(m)\n",
    "\n",
    "#- Now call with no PREVIOUS\n",
    "final_no_mem = memory_manager.invoke({\"messages\": conversation3, \"existing\": []})\n",
    "print(\"After FOURTH conversation: NO PREVIOUS MEMORIES::\")\n",
    "for m in final_no_mem:\n",
    "    print(m)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use these in a chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some basic examples for `entrypoint`. This will wrap a function and create a LangGraph out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the review_workflow::entry:point::: previous value=None\n",
      "{'compose_essay': 'An essay about dogs'}\n",
      "{'__interrupt__': (Interrupt(value={'question': 'Please provide a review', 'essay': 'An essay about dogs'}, resumable=True, ns=['review_workflow:18eceb1f-54c5-cae6-4b8f-9495cb4503ba'], when='during'),)}\n",
      "In the review_workflow::entry:point::: previous value=None\n",
      "{'review_workflow': {'essay': 'An essay about dogs', 'review': 'This essay is great.'}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from langgraph.func import entrypoint, task\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "@task\n",
    "def compose_essay(topic: str) -> str:\n",
    "    time.sleep(1.0)  # Simulate slow operation\n",
    "    return f\"An essay about {topic}\"\n",
    "\n",
    "# - previous value is accessible only if check pointer Memory saver is there\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def review_workflow(topic: str, previous: Optional[str] = None) -> dict:\n",
    "    print(f\"In the review_workflow::entry:point::: previous value={previous}\")\n",
    "    essay_future = compose_essay(topic)\n",
    "    essay = essay_future.result()\n",
    "    human_review = interrupt({\"question\": \"Please provide a review\",\"essay\": essay})\n",
    "\n",
    "    #- if we want to return a diferent value and save different then use the below. \n",
    "    # #- save is what gets saved in the chekpoiint available for NEXT invocations. value is what gets returned\n",
    "    #- entrypoint.final(value=previous, save=2 * number)\n",
    "    \n",
    "    #- either return this simple value\n",
    "    final_result = {\"essay\": essay,\"review\": human_review,}\n",
    "    # return final_result\n",
    "\n",
    "    return entrypoint.final(value=final_result, save=essay) # return the dict but save just the essay \n",
    "\n",
    "# Example configuration for the workflow\n",
    "config = {\"configurable\": {\"thread_id\": \"some_thread\"}}\n",
    "\n",
    "# Topic for the essay\n",
    "topic = \"dogs\"\n",
    "\n",
    "# Stream the workflow to generate the essay and await human review\n",
    "for result in review_workflow.stream(topic, config):\n",
    "    print(result)\n",
    "\n",
    "# Example human review provided after the interrupt\n",
    "human_review = \"This essay is great.\"\n",
    "\n",
    "# Resume the workflow with the provided human review\n",
    "for result in review_workflow.stream(Command(resume=human_review), config):\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUT::namespace=('chat', 'usr123', 'triples'), key=3057ffa8-a1d8-49ed-ad34-a5d690337cc1, value={'kind': 'Triple', 'content': {'subject': 'Alice', 'predicate': 'manages', 'object': 'ML team', 'context': None}}:PUT::namespace=('chat', 'usr123', 'triples'), key=360e7daa-87fe-46dd-b2e7-fd5315ecf59b, value={'kind': 'Triple', 'content': {'subject': 'Alice', 'predicate': 'mentors', 'object': 'Bob', 'context': None}}:\n",
      "PUT::namespace=('chat', 'usr123', 'triples'), key=a592daa6-44b4-4bbc-8d6f-217d9d0f8136, value={'kind': 'Triple', 'content': {'subject': 'Bob', 'predicate': 'is_on', 'object': 'ML team', 'context': None}}:\n",
      "\n",
      "[]\n",
      "content='Okay, got it. Alice is the manager of the ML (machine learning) team, and she mentors Bob, who is also a member of the same ML team.' additional_kwargs={} response_metadata={'ResponseMetadata': {'RequestId': 'd58adf81-b7ed-4e1b-b92f-f61de5cb42f1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 01:46:27 GMT', 'content-type': 'application/json', 'content-length': '313', 'connection': 'keep-alive', 'x-amzn-requestid': 'd58adf81-b7ed-4e1b-b92f-f61de5cb42f1'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [609]}} id='run-47a0536a-c4db-4b3f-a827-ecbd2b43226b-0' usage_metadata={'input_tokens': 30, 'output_tokens': 39, 'total_tokens': 69}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.func import entrypoint\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore()) \n",
    "#in_memory_store = InMemoryStore()\n",
    "#bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "class Triple(BaseModel): # \n",
    "    \"\"\"Store all new facts, preferences, and relationships as triples.\"\"\"\n",
    "    subject: str\n",
    "    predicate: str\n",
    "    object: str\n",
    "    context: str | None = None\n",
    "    \n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "memory_manager = create_memory_store_manager(\n",
    "    llm,\n",
    "    namespace=(\"chat\", \"{user_id}\", \"triples\"),\n",
    "    schemas=[Triple],\n",
    "    instructions=\"Extract all user information and events as triples.\",\n",
    "    enable_inserts=True,\n",
    "    enable_deletes=True,\n",
    ")\n",
    "\n",
    "# Run extraction in background\n",
    "@entrypoint(store=in_memory_store)  # (1)\n",
    "def app(messages: list):\n",
    "    response = llm.invoke(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            *messages,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Extract and store triples (Uses store from @entrypoint context)\n",
    "    memory_manager.invoke({\"messages\": messages})\n",
    "    return response\n",
    "\n",
    "#- no implemented for simple apps with entry-point\n",
    "#display(Image(app.get_graph().draw_mermaid_png()))\n",
    "\n",
    "res = app.invoke(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice manages the ML team and mentors Bob, who is also on the team.\",\n",
    "        }\n",
    "    ],\n",
    "    {\"configurable\": {\"user_id\": \"usr123\"}}\n",
    ")\n",
    "\n",
    "print(in_memory_store.search((\"memories\",)))\n",
    "\n",
    "print(res)\n",
    "\n",
    "# [\n",
    "#     Item(\n",
    "#         namespace=[\"memories\"],\n",
    "#         key=\"5ca8dacc-7d46-40bb-9b3d-f4c2dc5c4b30\",\n",
    "#         value={\"content\": \"Alice is the manager of the ML (Machine Learning) team\"},\n",
    "#         created_at=\"2025-02-11T00:28:01.688490+00:00\",\n",
    "#         updated_at=\"2025-02-11T00:28:01.688499+00:00\",\n",
    "#         score=None,\n",
    "#     ),\n",
    "#     Item(\n",
    "#         namespace=[\"memories\"],\n",
    "#         key=\"586783fa-e501-4835-8651-028c2735f0d0\",\n",
    "#         value={\"content\": \"Bob works on the ML team\"},\n",
    "#         created_at=\"2025-02-11T00:28:04.408826+00:00\",\n",
    "#         updated_at=\"2025-02-11T00:28:04.408841+00:00\",\n",
    "#         score=None,\n",
    "#     ),\n",
    "#     Item(\n",
    "#         namespace=[\"memories\"],\n",
    "#         key=\"19f75f64-8787-4150-a439-22068b00118a\",\n",
    "#         value={\"content\": \"Alice mentors Bob on the ML team\"},\n",
    "#         created_at=\"2025-02-11T00:28:06.951838+00:00\",\n",
    "#         updated_at=\"2025-02-11T00:28:06.951847+00:00\",\n",
    "#         score=None,\n",
    "#     ),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IN PROMPT:: we will search the store for memories and ADD to the system messages::QUERY=Alice manages the ML team and mentors Bob, who is also on the team.::state={'messages': [HumanMessage(content='Alice manages the ML team and mentors Bob, who is also on the team.', additional_kwargs={}, response_metadata={}, id='6ceb8fe6-dd7a-4e59-8f44-8ad4db035260')], 'is_last_step': False, 'remaining_steps': 24}::\n",
      "PUT::namespace=('memories',), key=e4436fe8-1e35-42bb-a536-9498ca5e78ad, value={'content': '{\\n  \"type\": \"person\",\\n  \"name\": \"Alice\",\\n  \"role\": \"manager\",\\n  \"team\": \"ML team\",\\n  \"mentors\": [\"Bob\"]\\n}'}:\n",
      " IN PROMPT:: we will search the store for memories and ADD to the system messages::QUERY=created memory e4436fe8-1e35-42bb-a536-9498ca5e78ad::state={'messages': [HumanMessage(content='Alice manages the ML team and mentors Bob, who is also on the team.', additional_kwargs={}, response_metadata={}, id='6ceb8fe6-dd7a-4e59-8f44-8ad4db035260'), AIMessage(content=[{'type': 'text', 'text': \"Okay, let's capture this information in our memories:\"}, {'type': 'tool_use', 'name': 'manage_memory', 'input': {'action': 'create', 'content': '{\\n  \"type\": \"person\",\\n  \"name\": \"Alice\",\\n  \"role\": \"manager\",\\n  \"team\": \"ML team\",\\n  \"mentors\": [\"Bob\"]\\n}'}, 'id': 'tooluse_X1vVM1O8TZylgmEh2Fpoag'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'ff3f1255-f444-47ee-ad85-474316eca11f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 02:04:43 GMT', 'content-type': 'application/json', 'content-length': '492', 'connection': 'keep-alive', 'x-amzn-requestid': 'ff3f1255-f444-47ee-ad85-474316eca11f'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1843]}}, id='run-a1a567b5-121c-499c-a7d7-aa36e05ad216-0', tool_calls=[{'name': 'manage_memory', 'args': {'action': 'create', 'content': '{\\n  \"type\": \"person\",\\n  \"name\": \"Alice\",\\n  \"role\": \"manager\",\\n  \"team\": \"ML team\",\\n  \"mentors\": [\"Bob\"]\\n}'}, 'id': 'tooluse_X1vVM1O8TZylgmEh2Fpoag', 'type': 'tool_call'}], usage_metadata={'input_tokens': 729, 'output_tokens': 129, 'total_tokens': 858}), ToolMessage(content='created memory e4436fe8-1e35-42bb-a536-9498ca5e78ad', name='manage_memory', id='eebea204-155e-4795-9e5a-f6261f6b6b26', tool_call_id='tooluse_X1vVM1O8TZylgmEh2Fpoag')], 'is_last_step': False, 'remaining_steps': 22}::\n",
      "ALL :MEMORIES:SO FAR::[Item(namespace=['memories'], key='e4436fe8-1e35-42bb-a536-9498ca5e78ad', value={'content': '{\\n  \"type\": \"person\",\\n  \"name\": \"Alice\",\\n  \"role\": \"manager\",\\n  \"team\": \"ML team\",\\n  \"mentors\": [\"Bob\"]\\n}'}, created_at='2025-03-01T02:04:43.702998+00:00', updated_at='2025-03-01T02:04:43.703011+00:00', score=None)]:\n",
      "content='Okay, got it. Alice is the manager of the ML (machine learning) team, and she mentors Bob, who is also a member of the same ML team.' additional_kwargs={} response_metadata={'ResponseMetadata': {'RequestId': '11594a48-ae65-404d-acda-3acf2b5003f3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 02:04:41 GMT', 'content-type': 'application/json', 'content-length': '313', 'connection': 'keep-alive', 'x-amzn-requestid': '11594a48-ae65-404d-acda-3acf2b5003f3'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [549]}} id='run-8fe00f12-5c51-4d40-88cf-e46ee825f659-0' usage_metadata={'input_tokens': 30, 'output_tokens': 39, 'total_tokens': 69}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.func import entrypoint\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore()) \n",
    "#in_memory_store = InMemoryStore()\n",
    "#bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def prompt(state):\n",
    "    \"\"\"Prepare messages with context from existing memories.\"\"\"\n",
    "    print(f\" IN PROMPT:: we will search the store for memories and ADD to the system messages::QUERY={state['messages'][-1].content}::state={state}::\")\n",
    "    \n",
    "    memories = in_memory_store.search(\n",
    "        (\"memories\",),\n",
    "        query=state[\"messages\"][-1].content,\n",
    "    )\n",
    "    system_msg = f\"\"\"You are a memory manager. Extract and manage all important knowledge, rules, and events using the provided tools.\n",
    "\n",
    "\n",
    "\n",
    "Existing memories:\n",
    "<memories>\n",
    "{memories}\n",
    "</memories>\n",
    "\n",
    "Use the manage_memory tool to update and contextualize existing memories, create new ones, or delete old ones that are no longer valid.\n",
    "You can also expand your search of existing memories to augment using the search tool.\"\"\"\n",
    "    return [{\"role\": \"system\", \"content\": system_msg}, *state[\"messages\"]]\n",
    "\n",
    "\n",
    "# Create the memory extraction agent\n",
    "agent_memories = create_react_agent(\n",
    "    llm,\n",
    "    prompt=prompt,\n",
    "    tools=[\n",
    "        # Agent can create/update/delete memories\n",
    "        create_manage_memory_tool(namespace=(\"memories\",)),\n",
    "        create_search_memory_tool(namespace=(\"memories\",)),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Run extraction in background\n",
    "@entrypoint(store=in_memory_store)  # (1)\n",
    "def app(messages: list):\n",
    "    response = llm.invoke(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            *messages,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Extract and store triples (Uses store from @entrypoint context)\n",
    "    agent_memories.invoke({\"messages\": messages})\n",
    "    return response\n",
    "\n",
    "\n",
    "res = app.invoke(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice manages the ML team and mentors Bob, who is also on the team.\",\n",
    "        }\n",
    "    ],\n",
    "    {\"configurable\": {\"user_id\": \"usr123\"}}\n",
    ")\n",
    "\n",
    "print(f\"ALL :MEMORIES:SO FAR::{in_memory_store.search(('memories',))}:\")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will explore creating these from base ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORIES:ADD_FUNC():: memories OLD got =[]::, query=can you suggest me a good vacation:\n",
      "MEMORIES:ADD_FUNC():: memories got =[]::, update=I like to hike in the mountains in the Cascades in the USA::query=can you suggest me a good vacation:\n",
      "{'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None} [Item(namespace=['memories'], key='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', value={'kind': 'Triple', 'content': {'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None}}, created_at='2025-03-01T19:54:54.528448+00:00', updated_at='2025-03-01T19:54:54.528453+00:00', score=None)]\n",
      "MEMORIES:model_reply_add_func()::updated_memory=[ExtractedMemory(id='40f2a3bb-80f6-4e64-a6f5-bc5556ea4e1a', content=Triple(subject='User', predicate='prefers', object='hiking in mountains in the cascades in USA', context='session_ffaea226-3fc1-41c2-bfd8-b1c6ed1a813e')), ExtractedMemory(id='585b139e-5f8c-4f5d-8c60-7b1c413cac08', content=Triple(subject='User', predicate='prefers', object='Mount Rainier National Park', context='session_ffaea226-3fc1-41c2-bfd8-b1c6ed1a813e')), ExtractedMemory(id='04723e46-06e0-494f-9249-09b6430dd845', content=Triple(subject='User', predicate='prefers', object='North Cascades National Park', context='session_ffaea226-3fc1-41c2-bfd8-b1c6ed1a813e')), ExtractedMemory(id='a8cc9ae9-c223-4cba-ba10-e8b4f2f539a4', content=Triple(subject='User', predicate='prefers', object='Mount Hood National Forest', context='session_ffaea226-3fc1-41c2-bfd8-b1c6ed1a813e')), ExtractedMemory(id='c29de050-a6e8-4c28-88ad-8190df071484', content=Triple(subject='User', predicate='prefers', object='Leavenworth, Washington', context='session_ffaea226-3fc1-41c2-bfd8-b1c6ed1a813e')), ExtractedMemory(id='693f8423-2b53-4da6-a182-77bea64276ba', content=Triple(subject='User', predicate='vacation', object='i like to hike in mountains in the cascades in USA', context=None))]::type=<class 'list'>::\n",
      "MEMORIES:model_reply_add_func():: exisiting_memories got =[Item(namespace=['memories'], key='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', value={'kind': 'Triple', 'content': {'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None}}, created_at='2025-03-01T19:54:54.528448+00:00', updated_at='2025-03-01T19:54:54.528453+00:00', score=None)]::, update=i like to hike in mountains in the cascades in USA::query=Okay, let me see what I can find for a good hiking vacation in the Cascade mountains in the USA based on your preferences.\n",
      "\n",
      "After searching, here are some recommendations for a great hiking vacation in the Cascades:\n",
      "\n",
      "1. Mount Rainier National Park (Washington):\n",
      "- This iconic mountain offers stunning alpine scenery, glaciers, and over 260 miles of hiking trails. Some top hikes include the Skyline Trail, Wonderland Trail, and the hike to Camp Muir.\n",
      "- The park has excellent facilities, including lodges, campgrounds, and visitor centers to support your hiking adventures.\n",
      "\n",
      "2. North Cascades National Park (Washington):\n",
      "- Known as the \"American Alps\", this park has dramatic peaks, glaciers, and pristine wilderness. Great hikes include the Cascade Pass Trail, Sahale Arm, and the Maple Pass Loop.\n",
      "- The park has fewer crowds than some other Cascade destinations, offering a more remote and rugged hiking experience.\n",
      "\n",
      "3. Mount Hood National Forest (Oregon):\n",
      "- Centered around the iconic Mount Hood, this forest has hundreds of miles of hiking trails through old-growth forests, alpine meadows, and to stunning viewpoints.\n",
      "- Popular hikes include the Timberline Trail, Tamanawas Falls, and the Bald Mountain Loop.\n",
      "\n",
      "4. Leavenworth, Washington:\n",
      "- This Bavarian-themed town in the Cascades is a great base for hiking, with trails like the Icicle Gorge Loop and the Enchantments.\n",
      "- The town also offers charming shops, restaurants, and lodging to complement your hiking adventures.\n",
      "\n",
      "Let me know if you need any other details on these Cascade hiking destinations or if you'd like me to look into any other options! I'm happy to provide more personalized recommendations.:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Okay, let me see what I can find for a good hiking vacation in the Cascade mountains in the USA based on your preferences.\\n\\nAfter searching, here are some recommendations for a great hiking vacation in the Cascades:\\n\\n1. Mount Rainier National Park (Washington):\\n- This iconic mountain offers stunning alpine scenery, glaciers, and over 260 miles of hiking trails. Some top hikes include the Skyline Trail, Wonderland Trail, and the hike to Camp Muir.\\n- The park has excellent facilities, including lodges, campgrounds, and visitor centers to support your hiking adventures.\\n\\n2. North Cascades National Park (Washington):\\n- Known as the \"American Alps\", this park has dramatic peaks, glaciers, and pristine wilderness. Great hikes include the Cascade Pass Trail, Sahale Arm, and the Maple Pass Loop.\\n- The park has fewer crowds than some other Cascade destinations, offering a more remote and rugged hiking experience.\\n\\n3. Mount Hood National Forest (Oregon):\\n- Centered around the iconic Mount Hood, this forest has hundreds of miles of hiking trails through old-growth forests, alpine meadows, and to stunning viewpoints.\\n- Popular hikes include the Timberline Trail, Tamanawas Falls, and the Bald Mountain Loop.\\n\\n4. Leavenworth, Washington:\\n- This Bavarian-themed town in the Cascades is a great base for hiking, with trails like the Icicle Gorge Loop and the Enchantments.\\n- The town also offers charming shops, restaurants, and lodging to complement your hiking adventures.\\n\\nLet me know if you need any other details on these Cascade hiking destinations or if you\\'d like me to look into any other options! I\\'m happy to provide more personalized recommendations.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'cc165e11-f5fb-4d0c-ba29-4ce26d6045e5', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 01 Mar 2025 19:54:59 GMT', 'content-type': 'application/json', 'content-length': '1872', 'connection': 'keep-alive', 'x-amzn-requestid': 'cc165e11-f5fb-4d0c-ba29-4ce26d6045e5'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [4404]}}, id='run-a643d7bf-f400-4cba-9f75-62831915a052-0', usage_metadata={'input_tokens': 116, 'output_tokens': 402, 'total_tokens': 518})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langgraph.utils.config import get_store \n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langmem.knowledge.extraction import ExtractedMemory\n",
    "import os\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import display, Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# Set up storage \n",
    "in_memory_store = CustomMemoryStore(InMemoryStore()) \n",
    "#in_memory_store = InMemoryStore()\n",
    "#bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "session = boto3.Session()\n",
    "# Create a new client with fresh credentials\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant capable of providing travel recommendations.\"\n",
    "            \" Use the provided tools to look for personalized travel recommendations and information about specific destinations.\"\n",
    "            \" If you dont have enough information then use AskHuman tool to get required information. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \" Existing memories: are below. \",\n",
    "        ),\n",
    "        (\"placeholder\",\"{memories}\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class Triple(BaseModel): # \n",
    "    \"\"\"Store all new facts, preferences, and relationships as triples.\"\"\"\n",
    "    subject: str\n",
    "    predicate: str\n",
    "    object: str\n",
    "    context: str | None = None\n",
    "\n",
    "# Configure extraction\n",
    "memory_manager = create_memory_manager(  \n",
    "    llm,\n",
    "    schemas=[Triple], \n",
    "    instructions=\"Extract user preferences and any other useful information\",\n",
    "    enable_inserts=True,\n",
    "    enable_deletes=True,\n",
    "    enable_updates=True\n",
    ")\n",
    "\n",
    "#- second way to create a callback runnable function--\n",
    "def memories_add_func(input_dict: dict, config: RunnableConfig) -> dict:\n",
    "    #print(f\"memories_add_func::input_dict:{input_dict}::config={config}\") #- if we do dict at start of chain -- {'input': {'input': 'what is the weather like in Seattle WA?', 'chat_history':\n",
    "    store = in_memory_store #get_store() # Same as that provided to `create_react_agent`\n",
    "    \n",
    "\n",
    "    memories = store.search(\n",
    "        # Search within the same namespace as the one\n",
    "        # we've configured for the agent\n",
    "        (\"memories\",),\n",
    "        query=input_dict[\"messages\"][-1].content,\n",
    "    ) \n",
    "    print(f\"MEMORIES:ADD_FUNC():: memories OLD got ={memories}::, query={input_dict['messages'][-1].content}:\")\n",
    "\n",
    "    #- update=[ExtractedMemory(id='e5c22c4a-232f-4ccd-a01c-f89e3b5641f2', content=Triple(subject='user',predicate='preferences', object='[]', context=None))]\n",
    "    #- [Item(namespace=['memories'], key='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', value={'kind': 'Triple', 'content': {'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None}}\n",
    "    #- ExtractedMemory(id='6dd5698a-6c9a-4180-a814-bdf9577d13ec', content=Triple(subject='Alice', predicate='manages', object='ML team', context=None))\n",
    "    #exisiting_mem = [Item(namespace=(\"memories\",), key='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', value=Triple(subject='User', predicate='Vacation', object='i like to hike in mountains in the cascades in USA'),  created_at='2025-02-25T19:58:57.511231+00:00', updated_at='2025-02-25T19:58:57.511234+00:00'),]\n",
    "    exisiting_mem = [ExtractedMemory(id='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', content=Triple(subject='User', predicate='Vacation', object='i like to hike in mountains in the cascades in USA')),]\n",
    "\n",
    "    updated_memory = memory_manager.invoke({\"messages\": input_dict[\"messages\"], \"existing\": exisiting_mem}) #memories})\n",
    "    if updated_memory:\n",
    "        updated_memory = updated_memory[-1].content.object # ExtractedMemory\n",
    "\n",
    "    print(f\"MEMORIES:ADD_FUNC():: memories got ={memories}::, update={updated_memory}::query={input_dict['messages'][-1].content}:\")\n",
    "    \n",
    "    #- simulate some old memory - ideally we would have used the updated_memory above\n",
    "    input_dict['memories'] = [HumanMessage(\"i like to hike in mountains in the cascades in USA\")] #update\n",
    "\n",
    "    #- update the store with this new memory\n",
    "    #- key=e61cdd0f-3650-4278-b762-02f0fe2fd6c4, value={'kind': 'Triple', 'content': {'subject': 'Bob', 'predicate': 'is_on', 'object': 'ML team', 'context': None}}\n",
    "    store.store.put(\n",
    "        namespace=(\"memories\",),\n",
    "        key='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', \n",
    "        value={'kind': 'Triple', 'content': {'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None}}\n",
    "    )\n",
    "\n",
    "    return input_dict\n",
    "    #return input_dict # return the text as is\n",
    "    #return [{\"role\": \"system\", \"content\": system_msg}, *state[\"messages\"]]\n",
    "\n",
    "\n",
    "#- second way to create a callback runnable function--\n",
    "def model_reply_add_func(model_output: AIMessage | HumanMessage, config: RunnableConfig) -> dict:\n",
    "    # - here since this is atthee nd of the chain we ONLY get AiMessage in the input_dict object - it is not really a dict\n",
    "    store = in_memory_store #get_store() # Same as that provided to `create_react_agent`\n",
    "    #print(input_dict, type(input_dict))\n",
    "    exisiting_mem = store.search((\"memories\",), query=model_output.content,) \n",
    "    print(exisiting_mem[-1].value['content'],exisiting_mem)\n",
    "    #- expects a list of Messages and a list of Triple Object \n",
    "    trp_dict = exisiting_mem[-1].value['content']\n",
    "    mem_id='693f8423-2b53-4da6-a182-77bea64276ba'\n",
    "    updated_memory = memory_manager.invoke({\"messages\": [model_output,], \"existing\": [(mem_id,Triple(**trp_dict)),]}) #memories})\n",
    "    # The manager will upsert; working with the existing memory instead of always creating a new one\n",
    "    print(f\"MEMORIES:model_reply_add_func()::updated_memory={updated_memory}::type={type(updated_memory)}::\")\n",
    "\n",
    "    if updated_memory:\n",
    "        updated_memory = updated_memory[-1].content.object # ExtractedMemory\n",
    "\n",
    "    print(f\"MEMORIES:model_reply_add_func():: exisiting_memories got ={exisiting_mem}::, update={updated_memory}::query={model_output.content}:\")\n",
    "\n",
    "    return model_output\n",
    "\n",
    "\n",
    "memories_add = RunnableLambda(memories_add_func)\n",
    "memories_model_update = RunnableLambda(model_reply_add_func)\n",
    "\n",
    "tools=[\n",
    "    # Agent can create/update/delete memories - these cannot be used for bind_tools issue raised\n",
    "    #convert_to_openai_tool(create_manage_memory_tool(namespace=(\"memories\",))),\n",
    "    #convert_to_openai_tool(create_search_memory_tool(namespace=(\"memories\",))),\n",
    "],\n",
    "\n",
    "runnable_with_tools = RunnablePassthrough() | memories_add | primary_assistant_prompt | llm | memories_model_update#.bind_tools(tools)\n",
    "\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    response = runnable_with_tools.invoke(state)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "runnable_with_tools.invoke({\"messages\":[HumanMessage(\"can you suggest me a good vacation\"),], \"configurable\": {\"user_id\": \"usr123\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# Define nodes: these do the work\n",
    "graph_builder.add_node(\"travel_planner\", call_model) \n",
    "# Define edges: these determine how the control flow moves\n",
    "graph_builder.add_edge(START, \"travel_planner\")\n",
    "\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# this is a complete memory for the entire graph.\n",
    "memory = MemorySaver()\n",
    "travel_planner_agent = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACGCAIAAABv+54xAAAAAXNSR0IArs4c6QAAE9dJREFUeJztnXlYE+e+x9/JTPaFJIRNlrCKyqbgCgqnihaxWj221t2qvW2PtFf66GOP2lafnnp6b9XrvafqsUfsYtWqXRQLdRdxo7ayySYiO0kgIQQSss9k7h/xQQ8GCDpJzDSfhz+SeSe/+ZJv3pl3+c28EI7jwMNzD8XVAjzYhccn98Djk3vg8ck98PjkHnh8cg8Q5x8Sx/GOZqNWjeo0GIbiJoPF+RqGC41BQRCIxYNZXNg/lOl8AZDT+k+4Ba/5TdNQ2dtUpQuOZlJpFBYX5vvSTHp38IlJUclNOjWG43hztS4slh0Wyx49kec0AU7yqeSKqqywWzyaFR7LCYtlO+GIjsNiwRsrtY2V2qZq7cQXhfHT+E44qMN9aq3VnT/cPnoSL2WeyKEHcj6o2XLzjLKhonf26gB/McOhx3KsT6VXVW11+vSlfkw27LijuJbebvTsV7Ixk3kxU7wcdxQH+lRxs6dHYZ46n2zVyCZXTsiDRzKjxnEdFN9RPl07pQAWkLrQxxHBn08uHevgCpBJs70dEdwh/afq22qzwfKHMgkAkL7UTykz1d/tdURw4n2StxokD3QzlvgRHvn5J3NNQO0dTbfCRHhk4n26fqrToVfU55zRk3g3TncSHpZgnxqrtHQmZUS4C3rszwlhMWyj3iJt0BMblmCfau9oUl7+QzTwBmHqfFH1rz3ExiTSJ5Xc1CkxCnxpBMZ0R/xCGM01ep0GJTAmkT41VmqdPyZ08uTJ7du3P8UH09PTpVKpAxQBAEBYLLuxUktgQCJ9krcYIhM4BAa0h5qamqf4VHt7e3d3twPkPCRqLEfWZCAwIJHzGpJ6Q+pCR02UlJaW7tu378GDBxiGjRw5MisrKzEx8c033ywpKQEA5OXlHT16NDIy8uDBg+fOnZPL5V5eXmlpaevXr2cymQCA999/H4Kg0NDQI0eOrFmzZv/+/QCAefPmpaWl7d69m3C1XCEiayDSJ4AThMVi+Ty7jqho/dDpdKmpqTt27GhoaKivr//0009TUlJ6eno0Gs2yZcs2b96sUqlQFD18+PCkSZPOnz/f3NxcVFSUkZGxc+dOa4StW7cuXLhw/fr1xcXFCoXiwoULSUlJNTU1vb29jhBsNGAHNj0gMCBhP3+dBmNxHTXY2t7ertVqMzMzw8LCAAAbN26cOXMmjUZjMBgIgtBoND6fDwCYPXv2lClTIiMjAQAhISGzZs26efNmX5C2trZDhw55eXkBANhsNgCAx+NZXxAOjU4BEDAZLDQGMVcWwnzCUJzpMJ9CQkLEYvEHH3zwyiuvTJ48OTo6Oikp6cnd+Hx+fn7+J598IpfLURTV6XQsFquvVCwWW01yDiwugmEWoloAhLUj2DxE1UH8eIkVGIZzcnLS09NPnTq1fPnyuXPn5ufnP7nbzp07c3JyFi1adPDgwWPHji1YsODxUg7HeW0cDMU1KjOTTVg1IMwnGIGoNIpBhxEVsB8CgSA7Ozs3N/fkyZMTJ07ctm1bv5YehmG5ubmrVq3KzMwMDAwUiUS9vQ4ZErUHrRpl84hsUhHZLg+OZunURHbu+pBIJFevXrW+Dg8P37JlC4VCqa+vt26xTs1YLBYMw/rObFqt9tq1a4PP2jhu7k2rRgOjiBw8I9Invg+1/i6Rnbs+2tvbN23adOTIkaampubm5pycHAqFEhcXBwDgcrm1tbW1tbVarTY6OjovL6+tra2uri47OzslJUWtVjc1NaFo/18Pj8cDANy4caOhocERguvLtd7+RI7LEOlTeCy7gdBOeB9JSUnbtm3Lz89fvnz5ypUrb9++vWvXLrFYDABYvHixQqFYu3ZtTU3NRx99hGHYokWLNm/evHjx4qysLH9//5UrV8rl8n4BR48enZycvGfPns8++8wRggkfmiF4PvfMF9L0pb4srgvSAp8fuhWmW3nKzNUBBMYkeLw8IoH9a34XsTHdjqI85chEghMlCP7hx0z2Krnc3K0w8X1sn50XLVr05FnI2lqD4QG7X7m5uQ7q+pSVlWVnZ9ssGlzSlStXKBQbv3J5i0GtQgkf5yQ+j6WxsretTj9tge3kCOs4zZPbURSFYRiCIJuf4nA4AxU9IyiK6vW25/QGl8Tl2q4xBSc7osZxg6JYNkufGofkGxXlKakMaHy6kPDIzzk3z3QyOXDidAHhkR2SbzTlJW9Zg4HwOc3nnJIClbYHdYRJjs2zLDgp9w2m/0FyWkqvqgxabMocR+UcODZv+dJ3HUw2TL7M8n5cPt5BpVFS/+zAfEWH3wdQXthdfFmVPNd71ATn3YXiNCqLem6dUU59WTRmsmP/O2fcV6NVo7d+VqqV5ogETngsm+dNdfQRHY1Kbmqq0lb/ph4Rykye501nOvwuB+fdp6aUGat/VTdUaql0SlAkk86ksL0QroCKYW7woBEYhjRd5t4eFDXhTTVagIPQGHbcVJ6Xt5OSq5znUx9KqbGjxdjbg2p7UBiGNN1EDrFbLJaysrLExEQCYwIAeAIqilk4XgjHC/EPZQj8nJ375gKfHIrJZEpLSysqKnK1EILx3O/uHnh8cg9I6FNsbKyrJRAPCX2qrKx0tQTiIZtPEAQJBA4ZYXMtZPMJx3GVSuVqFcRDNp8gCAoODna1CuIhm084jre2trpaBfGQzScAwLhx41wtgXhI6FNpaamrJRAPCX0iJWTzCYIgX19fV6sgHrL5hOO4zbwzd4dsPnnqk3vgqU8eXAnZfIIgaOTIka5WQTxk8wnH8fv377taBfGQzSeyQkKf4uPjXS2BeEjo0927d10tgXhI6BMpIaFPnvFy98AzXu7BZZDQJ09emHvgyQvz4DLI5pMnf8898OTvuQ2jRo1ytQTiIaFP9+7dc7UE4iGhT6SEbD5BEDRixAhXqyAesvmE47jjnvLvQsjmEwAgISHB1RKIh4Q+lZeXu1oC8ZDQJ099cg889ckNsC524moVxEOS53xkZWU1NjZaHxOqVCpFIhGO4yiKnj171tXSiIEk9Wnp0qUmk0kmk8lkMpPJJJVKZTJZR0eHq3URBkl8SklJiYqKenwLjuPJycmuU0QwJPEJALBixYrHn8nM4/FWr17tUkVEQh6fkpOTrSs/WUlISLC59pCbQh6fAAArV660VimhULhq1SpXyyESUvmUkpISERGB43hsbCzJsvgIWA/AoMN0GkynRs1G17fx5896y9B1/KXprztoRRb7oUCASqewuDCLBz/7g0mfvv/UWKmtK+vtlJrUSjONCVMZMMKAcdTlTj0vwAhk0mNmI2bSY1wh1V9Mj4hnh455ykVsnsan4suq+6Vai4XCErK4viyE6vCn2Lo7ZiOqket0Kh2C4KMncBJS+cONMDyfaos1hT8o+AEcn0ihgxa8IDcYZums79J06qa/5hMeO4y1UobhU+GPCkUH4Ad6ITRPBXomzAa0W9IdFI5MyfS28yP2+vTTXgmgMoQhw66wHgais1HFZqOzV/nbs7Nd7fL8rzoAjekxiVhEYQKtDrlwTGHPzkP7dOWE3IzRhMF/iOVMnIwoVNCrodz8uXPIPYfwqaqoR9UF8QNJuDTGc4IwhC9rxurK1IPvNphPuAUvOKnwDv3DLbflZARi4aWhzn6D+XT9dGdAtMckhwMjFO8Q3m/nBlt/c0CfdBq0tc7oLfZclpyBb4SwtqQXM1sG2mFAn+4XaxCms1f7GIRvvvvrga+ynvrjsvYHGz+c1NhcRqgoIkEYtPulAy5IP6BPdeU6tvfQi1YePr7595K8Z5Dn4SFsIetB2YBjx7Z9MuqxboWJIxx6Jfk2KQlvjnAJXF+WpF430LCD7XkNpdREZw495bHxw0kAgBOn/pZ7ds8nWy8fPr4ZAMjPJ/TqzaMrFu0YM2pqSfn5wptHFcoWBKGFBsfNy3xPJAyqrbt98PB/vvtmjjg4zhqnubXy83+t/Y9V/4iOnNQmvffLxf1t0nsYao6KmDBv9ntCgb0LcLdJ7/3vP1e9vuSz678el0hrKTAyYdxLc2a9029BYgzDLl09VHL3fI9azmJ6xYxOfenFd+k0JgDg8PEtEASio6YUXDvco1H4isQLXtpo1bn9vzJmpK3u7ukovXvBZNKFice++vIWHk8EAMAw9FLhV2UVF1XdMr6XX2rykuSJCwEAso763XuXrl6265cL+8QhcYvmbx1EPARBdBZVKTOJRtCfLLVdn3QaDLZjEO+DjT8DAObP2bD5vZ8AADBMbZfXt0nvvbFiT0hwbEtb1bEfPho1Mjn77a/fWLHHZNJ/891fAQCR4eM5bEFFdWFfnIqqAg5bEBk2XtXdfuDLdRSI8pc1+99es0+nU3/x9Ttm1DSkEiswBQEA5F/Ymzkz6+Mtl15b8OH1ouO/l/zcb7frRd9dufbN7PS3N2QdfW3Bh1U1185e/OfDCDDS2Fze0lqVve7w9vfPsVheJ3765OE3RUEKrn/r5xu2dcPpje9+J5HVXir80lqUd/7zwhtHpqeu2vjOsdTkJbn5/3P7Ti4AAIGpAICLBTlpU5dNTx16fhmhwzo1ZrNoIJ9QmDp0fWKzvAAAdBrL+gIAoOxqW7xwW0RYIofN9xGJ17/99awX3vD1CQ0JipmWvETWXqfp7YJhOD5memXN1b44FdUFCbHpMAwX/f4TgKBlr/4twC8yOHDMkle2d6kkFVVXhlTyOIkJGeLgWAqFEjNqWmRY0p2yX/rvEJ+Rve6bsXEzfUQh0VGTxsbNvP/gdl+pyaSfNzubTmPSaIzE+Ax5Z5PJZLAW+fmGTkycC8MI38svOmpKq6QGAKA39N66/UPa1OUTxs0ReQcnT1w4ftycK9cPW6sIACAiLGli4lyRMGhI5QgN1qptry5n2wwMw2H60wyK+3iL+zxjMjhdKunZi/s7u9pMZgOGmgEAer2ayxHGx8649duPso76AL+INuk9pUoyLn4WAKCltTIkcAyT+XBJbgHfXygIlMjuJyZk2K8hcMSj+z79fMPLKy/124HN5t8p/+X705/2qOWYBTUadXT6oxaTyDuYRmNYX7OYPACATq+2bgnwe5R6xmLydHo1AEAqu49Z0JERE/uKIsISbxfnGo0661txkL3Ps4DpCDbARKttn+hMGNUb7Yz+OAzGozmVsoqLR05+kJ625uU5G5h0TmNL+bcntliLwsXjeFxRZc3VAL+Iu1UFAn5AaEg8AEBv0Erba9/fPrUvCIaZ1Zqhh7/+TTztUfOHRmPqDZp+O5zO311cfnbh3PdDQ+KpCL3gxrelFRf6ShHkycvDw++OSrVx5bD6ceDLdeDRhBwOAND0Kp/8TgYH1ZsYLIbNIts+sbgwZrZ9orSfX++cjghLykh/y/rWZDb0FVEolPiYGZXVhTP/tLaiumBc3CzrdgaDHRYy9pWX//p4HBpteGvam0z6vtdGo5bJ4D5eimHYb8Vn0l9YkzR2tnWLwTBgr8UeGAw2AGDpqx8H+EU8vt3Ly6+nZ3gJuagJY/Fsn8ZsX5/YPITGtDcVCQe2qyqKmjnsR1MhpXfPW9NUrW8TYmdIZLV19b8rOputJz0AgDg4trOr1VsY5OsTav0DAOJxh7ecdX1jSd/rVkmNj0j8b2pxiwXHWMyHJ2eDQVtVex08QwJOgH8UDFN7e7v6NLNYXiwWn4oMe5SAzoTZPNs1x7YZPkH07nYDahyiSlGpdCqV3tBUKpHWYlj/C2BIUEztg9vNrZVdKtmPZ/6bxxFZvzjrZTk0JF7A9z9z7v8C/CID/B/mR04ev8Bo1B3/6WOJtFbR2XKx4NCuvUtaJVXD+m+raq+X3r2g7JIU3jzW3FoxMXHu46UIQg0MiC4u+6VT2SZtr/vyyIbRUck6vbpD0fTkv2APTAZnyoQF5wsOllVcVHZJHjQUf/H1uydOfTzcOEatWa82e4lsLwI9YKMudAxLrdAJg7gD7WDlhWkrr17/trr2xubsH/sVzUh7XdnV9sXX7zDo7Mnj56f/aa1ao/g+9+8UCpyY8CIEQfExMwpvHs2cua7vI0JBwNtr9udf2Lsv500KBfb3jVi9bFdfN8tOMma8dacs//vTOxAqPWPGW33ntz5enb/15Kkdu/YuEQpGZEx/KyQ4pqnl7j8OrN7wztFhHaiPuRnrmQxu/oW9ak0nl+M9Jnra7Jl/GW4QjUIXHjfgGX7Aefemau3tixq/kQ5cW55wZO0Pdu9blvXGF2Hisa7WMmzaazpS5wtGhNseAxrwIhQ6hm3UGA299vYxPTwLum4DwLGBTBoiH3bafNGts12BsXYlWjiHxuayQ0c2DFS6Ztlu58ohjM5GVfprgzWXhsg3OvMvGcLjsbxsN+qdD4qadbqegUq5XG93zCrsVeoQTJexym+QfYbwCcPwA5vqY9LDHCDPAwAAWDDLvcKWdTsjBt9tiE4SDEOvrg9qLpYQqs3DIxp/lyzdNPQCpXblWarkptwD7aETAgnS5uEhTXckf84K4Alt95kex65BB4EvbcZi0f3rLWbTsw4mebBi0qPVV5oyX/e1x6Th5ZfrNOi5bzpwmObJFHsWLBa8q6mLSkHnrPVHaPYOzg37vpriy6qiPGVwnDeDx6Sz7foteLBi6DUZ1HppTVfKXFFC2vCSwJ/yPrU7l1SVt9S4BXgFcCAYRugwlY5QEMgdm8UOA0JNKGrCUCOGoWiPrJdKhWJTeIkvPM1jhp/peSxdHaaWezp5q1GjQrVqDMdx1Oi5n/AhNBYMcJzFg7l8xE9ME49i832ePs+OJM/NIT2kut+dxHh8cg88PrkHHp/cA49P7oHHJ/fg/wF1JQScg6pe7QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(travel_planner_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Suggest me a good vacation destination.\n",
      "MEMORIES:ADD_FUNC():: memories OLD got =[Item(namespace=['memories'], key='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', value={'kind': 'Triple', 'content': {'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None}}, created_at='2025-03-01T19:54:54.528448+00:00', updated_at='2025-03-01T19:54:54.528453+00:00', score=None)]::, query=Suggest me a good vacation destination.:\n",
      "MEMORIES:ADD_FUNC():: memories got =[Item(namespace=['memories'], key='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', value={'kind': 'Triple', 'content': {'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None}}, created_at='2025-03-01T19:54:54.528448+00:00', updated_at='2025-03-01T19:54:54.528453+00:00', score=None)]::, update=I like to hike in the mountains in the Cascades in the USA::query=Suggest me a good vacation destination.:\n",
      "{'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None} [Item(namespace=['memories'], key='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', value={'kind': 'Triple', 'content': {'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None}}, created_at='2025-03-01T19:55:13.842722+00:00', updated_at='2025-03-01T19:55:13.842723+00:00', score=None)]\n",
      "MEMORIES:model_reply_add_func()::updated_memory=[ExtractedMemory(id='4e839c48-d43a-48ba-9a56-ee9ba47d4c1f', content=Triple(subject='User', predicate='prefers', object='hiking in mountains in the cascades in USA', context='session_20e5bc6a-ac32-4085-bf4e-96b3e7137d5d')), ExtractedMemory(id='693f8423-2b53-4da6-a182-77bea64276ba', content=Triple(subject='User', predicate='vacation', object='i like to hike in mountains in the cascades in USA', context=None))]::type=<class 'list'>::\n",
      "MEMORIES:model_reply_add_func():: exisiting_memories got =[Item(namespace=['memories'], key='e61cdd0f-3650-4278-b762-02f0fe2fd6c4', value={'kind': 'Triple', 'content': {'subject': 'User', 'predicate': 'vacation', 'object': 'i like to hike in mountains in the cascades in USA', 'context': None}}, created_at='2025-03-01T19:55:13.842722+00:00', updated_at='2025-03-01T19:55:13.842723+00:00', score=None)]::, update=i like to hike in mountains in the cascades in USA::query=Okay, let's look for a good hiking destination for you in the Cascade mountains in the USA.\n",
      "\n",
      "Based on your preference for hiking in the mountains, here are some recommendations in the Cascade range:\n",
      "\n",
      "1. Mount Rainier National Park (Washington):\n",
      "   - Mount Rainier is the centerpiece of this stunning national park, offering numerous hiking trails through alpine meadows, glaciers, and forests.\n",
      "   - Popular hikes include the Skyline Trail, Wonderland Trail, and the hike to the summit of Mount Rainier.\n",
      "\n",
      "2. North Cascades National Park (Washington):\n",
      "   - Known for its rugged, glacier-capped peaks, this park has an abundance of hiking trails showcasing the dramatic mountain scenery.\n",
      "   - Recommended hikes include the Cascade Pass Trail, Sahale Arm, and the Maple Pass Loop.\n",
      "\n",
      "3. Crater Lake National Park (Oregon):\n",
      "   - While not technically in the Cascades, Crater Lake is a stunning volcanic caldera that offers excellent hiking opportunities.\n",
      "   - Popular trails include the Rim Village to Cleetwood Cove Trail and the Watchman Peak Trail.\n",
      "\n",
      "4. Mount Hood National Forest (Oregon):\n",
      "   - Surrounding the iconic Mount Hood, this forest has numerous hiking trails through old-growth forests, alpine meadows, and past glacial features.\n",
      "   - Hikes to consider include the Timberline Trail and the Tamanawas Falls Trail.\n",
      "\n",
      "Let me know if you need any additional details or have a preference on a specific location within the Cascade range. I'm happy to provide more personalized recommendations.:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Okay, let's look for a good hiking destination for you in the Cascade mountains in the USA.\n",
      "\n",
      "Based on your preference for hiking in the mountains, here are some recommendations in the Cascade range:\n",
      "\n",
      "1. Mount Rainier National Park (Washington):\n",
      "   - Mount Rainier is the centerpiece of this stunning national park, offering numerous hiking trails through alpine meadows, glaciers, and forests.\n",
      "   - Popular hikes include the Skyline Trail, Wonderland Trail, and the hike to the summit of Mount Rainier.\n",
      "\n",
      "2. North Cascades National Park (Washington):\n",
      "   - Known for its rugged, glacier-capped peaks, this park has an abundance of hiking trails showcasing the dramatic mountain scenery.\n",
      "   - Recommended hikes include the Cascade Pass Trail, Sahale Arm, and the Maple Pass Loop.\n",
      "\n",
      "3. Crater Lake National Park (Oregon):\n",
      "   - While not technically in the Cascades, Crater Lake is a stunning volcanic caldera that offers excellent hiking opportunities.\n",
      "   - Popular trails include the Rim Village to Cleetwood Cove Trail and the Watchman Peak Trail.\n",
      "\n",
      "4. Mount Hood National Forest (Oregon):\n",
      "   - Surrounding the iconic Mount Hood, this forest has numerous hiking trails through old-growth forests, alpine meadows, and past glacial features.\n",
      "   - Hikes to consider include the Timberline Trail and the Tamanawas Falls Trail.\n",
      "\n",
      "Let me know if you need any additional details or have a preference on a specific location within the Cascade range. I'm happy to provide more personalized recommendations.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"4\", \"user_id\": 193}}\n",
    "\n",
    "input_message = HumanMessage(\n",
    "    content=\"Suggest me a good vacation destination.\"\n",
    ")\n",
    "for event in travel_planner_agent.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "trainenv",
   "language": "python",
   "name": "trainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
